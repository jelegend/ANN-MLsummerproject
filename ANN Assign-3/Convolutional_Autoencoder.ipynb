{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "Sticking with the MNIST dataset, let's improve our autoencoder's performance using convolutional layers. Again, loading modules and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8c515496db61>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1af8e095108>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "The encoder part of the network will be a typical convolutional pyramid. Each convolutional layer will be followed by a max-pooling layer to reduce the dimensions of the layers. The decoder though might be something new to you. The decoder needs to convert from a narrow representation to a wide reconstructed image. For example, the representation could be a 4x4x8 max-pool layer. This is the output of the encoder, but also the input to the decoder. We want to get a 28x28x1 image out from the decoder so we need to work our way back up from the narrow decoder input layer. A schematic of the network is shown below.\n",
    "\n",
    "<img src='assets/convolutional_autoencoder.png' width=500px>\n",
    "\n",
    "Here our final encoder layer has size 4x4x8 = 128. The original images have size 28x28 = 784, so the encoded vector is roughly 16% the size of the original image. These are just suggested sizes for each of the layers. Feel free to change the depths and sizes, but remember our goal here is to find a small representation of the input data.\n",
    "\n",
    "### What's going on with the decoder\n",
    "\n",
    "Okay, so the decoder has these \"Upsample\" layers that you might not have seen before. First off, I'll discuss a bit what these layers *aren't*. Usually, you'll see **transposed convolution** layers used to increase the width and height of the layers. They work almost exactly the same as convolutional layers, but in reverse. A stride in the input layer results in a larger stride in the transposed convolution layer. For example, if you have a 3x3 kernel, a 3x3 patch in the input layer will be reduced to one unit in a convolutional layer. Comparatively, one unit in the input layer will be expanded to a 3x3 path in a transposed convolution layer. The TensorFlow API provides us with an easy way to create the layers, [`tf.nn.conv2d_transpose`](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose). \n",
    "\n",
    "However, transposed convolution layers can lead to artifacts in the final images, such as checkerboard patterns. This is due to overlap in the kernels which can be avoided by setting the stride and kernel size equal. In [this Distill article](http://distill.pub/2016/deconv-checkerboard/) from Augustus Odena, *et al*, the authors show that these checkerboard artifacts can be avoided by resizing the layers using nearest neighbor or bilinear interpolation (upsampling) followed by a convolutional layer. In TensorFlow, this is easily done with [`tf.image.resize_images`](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/image/resize_images), followed by a convolution. Be sure to read the Distill article to get a better understanding of deconvolutional layers and why we're using upsampling.\n",
    "\n",
    "> **Exercise:** Build the network shown above. Remember that a convolutional layer with strides of 1 and 'same' padding won't reduce the height and width. That is, if the input is 28x28 and the convolution layer has stride = 1 and 'same' padding, the convolutional layer will also be 28x28. The max-pool layers are used the reduce the width and height. A stride of 2 will reduce the size by a factor of 2. Odena *et al* claim that nearest neighbor interpolation works best for the upsampling, so make sure to include that as a parameter in `tf.image.resize_images` or use [`tf.image.resize_nearest_neighbor`]( `https://www.tensorflow.org/api_docs/python/tf/image/resize_nearest_neighbor). For convolutional layers, use [`tf.layers.conv2d`](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d). For example, you would write `conv1 = tf.layers.conv2d(inputs, 32, (5,5), padding='same', activation=tf.nn.relu)` for a layer with a depth of 32, a 5x5 kernel, stride of (1,1), padding is 'same', and a ReLU activation. Similarly, for the max-pool layers, use [`tf.layers.max_pooling2d`](https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-202d5fea0cdc>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E876208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E876208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E876208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E876208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-4-202d5fea0cdc>:9: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E0430C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E0430C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E0430C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E0430C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E876108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E876108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E876108>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E876108>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E062088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E062088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E062088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E062088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8B111788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8B111788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8B111788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8B111788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8D0FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8D0FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8D0FC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8D0FC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8A4F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8A4F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8A4F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8A4F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E829B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8B111788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8B111788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8B111788>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8B111788>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x16\n",
    "conv2 = tf.layers.conv2d(maxpool1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x8\n",
    "conv3 = tf.layers.conv2d(maxpool2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "# Now 4x4x8\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x8\n",
    "conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x8\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x8\n",
    "conv5 = tf.layers.conv2d(upsample2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x8\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x8\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x16\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "As before, here we'll train the network. Instead of flattening the images though, we can pass them in as 28x28x1 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.6996\n",
      "Epoch: 1/20... Training loss: 0.6960\n",
      "Epoch: 1/20... Training loss: 0.6930\n",
      "Epoch: 1/20... Training loss: 0.6905\n",
      "Epoch: 1/20... Training loss: 0.6880\n",
      "Epoch: 1/20... Training loss: 0.6859\n",
      "Epoch: 1/20... Training loss: 0.6834\n",
      "Epoch: 1/20... Training loss: 0.6807\n",
      "Epoch: 1/20... Training loss: 0.6774\n",
      "Epoch: 1/20... Training loss: 0.6731\n",
      "Epoch: 1/20... Training loss: 0.6685\n",
      "Epoch: 1/20... Training loss: 0.6629\n",
      "Epoch: 1/20... Training loss: 0.6553\n",
      "Epoch: 1/20... Training loss: 0.6459\n",
      "Epoch: 1/20... Training loss: 0.6370\n",
      "Epoch: 1/20... Training loss: 0.6239\n",
      "Epoch: 1/20... Training loss: 0.6098\n",
      "Epoch: 1/20... Training loss: 0.5924\n",
      "Epoch: 1/20... Training loss: 0.5789\n",
      "Epoch: 1/20... Training loss: 0.5601\n",
      "Epoch: 1/20... Training loss: 0.5370\n",
      "Epoch: 1/20... Training loss: 0.5249\n",
      "Epoch: 1/20... Training loss: 0.5327\n",
      "Epoch: 1/20... Training loss: 0.5150\n",
      "Epoch: 1/20... Training loss: 0.5293\n",
      "Epoch: 1/20... Training loss: 0.5329\n",
      "Epoch: 1/20... Training loss: 0.5399\n",
      "Epoch: 1/20... Training loss: 0.5106\n",
      "Epoch: 1/20... Training loss: 0.4979\n",
      "Epoch: 1/20... Training loss: 0.4859\n",
      "Epoch: 1/20... Training loss: 0.4853\n",
      "Epoch: 1/20... Training loss: 0.4775\n",
      "Epoch: 1/20... Training loss: 0.4683\n",
      "Epoch: 1/20... Training loss: 0.4528\n",
      "Epoch: 1/20... Training loss: 0.4495\n",
      "Epoch: 1/20... Training loss: 0.4358\n",
      "Epoch: 1/20... Training loss: 0.4305\n",
      "Epoch: 1/20... Training loss: 0.4289\n",
      "Epoch: 1/20... Training loss: 0.4162\n",
      "Epoch: 1/20... Training loss: 0.4151\n",
      "Epoch: 1/20... Training loss: 0.4038\n",
      "Epoch: 1/20... Training loss: 0.3952\n",
      "Epoch: 1/20... Training loss: 0.3876\n",
      "Epoch: 1/20... Training loss: 0.3677\n",
      "Epoch: 1/20... Training loss: 0.3631\n",
      "Epoch: 1/20... Training loss: 0.3604\n",
      "Epoch: 1/20... Training loss: 0.3488\n",
      "Epoch: 1/20... Training loss: 0.3407\n",
      "Epoch: 1/20... Training loss: 0.3335\n",
      "Epoch: 1/20... Training loss: 0.3292\n",
      "Epoch: 1/20... Training loss: 0.3265\n",
      "Epoch: 1/20... Training loss: 0.3109\n",
      "Epoch: 1/20... Training loss: 0.2972\n",
      "Epoch: 1/20... Training loss: 0.2921\n",
      "Epoch: 1/20... Training loss: 0.2882\n",
      "Epoch: 1/20... Training loss: 0.2914\n",
      "Epoch: 1/20... Training loss: 0.2913\n",
      "Epoch: 1/20... Training loss: 0.2742\n",
      "Epoch: 1/20... Training loss: 0.2792\n",
      "Epoch: 1/20... Training loss: 0.2767\n",
      "Epoch: 1/20... Training loss: 0.2709\n",
      "Epoch: 1/20... Training loss: 0.2761\n",
      "Epoch: 1/20... Training loss: 0.2701\n",
      "Epoch: 1/20... Training loss: 0.2744\n",
      "Epoch: 1/20... Training loss: 0.2693\n",
      "Epoch: 1/20... Training loss: 0.2526\n",
      "Epoch: 1/20... Training loss: 0.2569\n",
      "Epoch: 1/20... Training loss: 0.2481\n",
      "Epoch: 1/20... Training loss: 0.2564\n",
      "Epoch: 1/20... Training loss: 0.2533\n",
      "Epoch: 1/20... Training loss: 0.2469\n",
      "Epoch: 1/20... Training loss: 0.2482\n",
      "Epoch: 1/20... Training loss: 0.2480\n",
      "Epoch: 1/20... Training loss: 0.2473\n",
      "Epoch: 1/20... Training loss: 0.2463\n",
      "Epoch: 1/20... Training loss: 0.2583\n",
      "Epoch: 1/20... Training loss: 0.2474\n",
      "Epoch: 1/20... Training loss: 0.2467\n",
      "Epoch: 1/20... Training loss: 0.2459\n",
      "Epoch: 1/20... Training loss: 0.2406\n",
      "Epoch: 1/20... Training loss: 0.2407\n",
      "Epoch: 1/20... Training loss: 0.2242\n",
      "Epoch: 1/20... Training loss: 0.2362\n",
      "Epoch: 1/20... Training loss: 0.2315\n",
      "Epoch: 1/20... Training loss: 0.2404\n",
      "Epoch: 1/20... Training loss: 0.2380\n",
      "Epoch: 1/20... Training loss: 0.2312\n",
      "Epoch: 1/20... Training loss: 0.2304\n",
      "Epoch: 1/20... Training loss: 0.2305\n",
      "Epoch: 1/20... Training loss: 0.2282\n",
      "Epoch: 1/20... Training loss: 0.2256\n",
      "Epoch: 1/20... Training loss: 0.2351\n",
      "Epoch: 1/20... Training loss: 0.2193\n",
      "Epoch: 1/20... Training loss: 0.2266\n",
      "Epoch: 1/20... Training loss: 0.2287\n",
      "Epoch: 1/20... Training loss: 0.2254\n",
      "Epoch: 1/20... Training loss: 0.2267\n",
      "Epoch: 1/20... Training loss: 0.2257\n",
      "Epoch: 1/20... Training loss: 0.2099\n",
      "Epoch: 1/20... Training loss: 0.2155\n",
      "Epoch: 1/20... Training loss: 0.2155\n",
      "Epoch: 1/20... Training loss: 0.2200\n",
      "Epoch: 1/20... Training loss: 0.2132\n",
      "Epoch: 1/20... Training loss: 0.2082\n",
      "Epoch: 1/20... Training loss: 0.2097\n",
      "Epoch: 1/20... Training loss: 0.2119\n",
      "Epoch: 1/20... Training loss: 0.2059\n",
      "Epoch: 1/20... Training loss: 0.2117\n",
      "Epoch: 1/20... Training loss: 0.1996\n",
      "Epoch: 1/20... Training loss: 0.2044\n",
      "Epoch: 1/20... Training loss: 0.2074\n",
      "Epoch: 1/20... Training loss: 0.2074\n",
      "Epoch: 1/20... Training loss: 0.1999\n",
      "Epoch: 1/20... Training loss: 0.1997\n",
      "Epoch: 1/20... Training loss: 0.2120\n",
      "Epoch: 1/20... Training loss: 0.2070\n",
      "Epoch: 1/20... Training loss: 0.2048\n",
      "Epoch: 1/20... Training loss: 0.2002\n",
      "Epoch: 1/20... Training loss: 0.2031\n",
      "Epoch: 1/20... Training loss: 0.2044\n",
      "Epoch: 1/20... Training loss: 0.2006\n",
      "Epoch: 1/20... Training loss: 0.2003\n",
      "Epoch: 1/20... Training loss: 0.1959\n",
      "Epoch: 1/20... Training loss: 0.1973\n",
      "Epoch: 1/20... Training loss: 0.2039\n",
      "Epoch: 1/20... Training loss: 0.1895\n",
      "Epoch: 1/20... Training loss: 0.1982\n",
      "Epoch: 1/20... Training loss: 0.1966\n",
      "Epoch: 1/20... Training loss: 0.1968\n",
      "Epoch: 1/20... Training loss: 0.1926\n",
      "Epoch: 1/20... Training loss: 0.1992\n",
      "Epoch: 1/20... Training loss: 0.1912\n",
      "Epoch: 1/20... Training loss: 0.1921\n",
      "Epoch: 1/20... Training loss: 0.1925\n",
      "Epoch: 1/20... Training loss: 0.1936\n",
      "Epoch: 1/20... Training loss: 0.1892\n",
      "Epoch: 1/20... Training loss: 0.1901\n",
      "Epoch: 1/20... Training loss: 0.1940\n",
      "Epoch: 1/20... Training loss: 0.1884\n",
      "Epoch: 1/20... Training loss: 0.1934\n",
      "Epoch: 1/20... Training loss: 0.1844\n",
      "Epoch: 1/20... Training loss: 0.1895\n",
      "Epoch: 1/20... Training loss: 0.1887\n",
      "Epoch: 1/20... Training loss: 0.1881\n",
      "Epoch: 1/20... Training loss: 0.1922\n",
      "Epoch: 1/20... Training loss: 0.1909\n",
      "Epoch: 1/20... Training loss: 0.1864\n",
      "Epoch: 1/20... Training loss: 0.1930\n",
      "Epoch: 1/20... Training loss: 0.1872\n",
      "Epoch: 1/20... Training loss: 0.1834\n",
      "Epoch: 1/20... Training loss: 0.1877\n",
      "Epoch: 1/20... Training loss: 0.1865\n",
      "Epoch: 1/20... Training loss: 0.1877\n",
      "Epoch: 1/20... Training loss: 0.1825\n",
      "Epoch: 1/20... Training loss: 0.1869\n",
      "Epoch: 1/20... Training loss: 0.1846\n",
      "Epoch: 1/20... Training loss: 0.1869\n",
      "Epoch: 1/20... Training loss: 0.1865\n",
      "Epoch: 1/20... Training loss: 0.1841\n",
      "Epoch: 1/20... Training loss: 0.1910\n",
      "Epoch: 1/20... Training loss: 0.1850\n",
      "Epoch: 1/20... Training loss: 0.1879\n",
      "Epoch: 1/20... Training loss: 0.1779\n",
      "Epoch: 1/20... Training loss: 0.1825\n",
      "Epoch: 1/20... Training loss: 0.1889\n",
      "Epoch: 1/20... Training loss: 0.1845\n",
      "Epoch: 1/20... Training loss: 0.1779\n",
      "Epoch: 1/20... Training loss: 0.1775\n",
      "Epoch: 1/20... Training loss: 0.1805\n",
      "Epoch: 1/20... Training loss: 0.1820\n",
      "Epoch: 1/20... Training loss: 0.1819\n",
      "Epoch: 1/20... Training loss: 0.1815\n",
      "Epoch: 1/20... Training loss: 0.1785\n",
      "Epoch: 1/20... Training loss: 0.1775\n",
      "Epoch: 1/20... Training loss: 0.1870\n",
      "Epoch: 1/20... Training loss: 0.1807\n",
      "Epoch: 1/20... Training loss: 0.1827\n",
      "Epoch: 1/20... Training loss: 0.1808\n",
      "Epoch: 1/20... Training loss: 0.1738\n",
      "Epoch: 1/20... Training loss: 0.1805\n",
      "Epoch: 1/20... Training loss: 0.1777\n",
      "Epoch: 1/20... Training loss: 0.1806\n",
      "Epoch: 1/20... Training loss: 0.1771\n",
      "Epoch: 1/20... Training loss: 0.1727\n",
      "Epoch: 1/20... Training loss: 0.1729\n",
      "Epoch: 1/20... Training loss: 0.1793\n",
      "Epoch: 1/20... Training loss: 0.1760\n",
      "Epoch: 1/20... Training loss: 0.1828\n",
      "Epoch: 1/20... Training loss: 0.1757\n",
      "Epoch: 1/20... Training loss: 0.1779\n",
      "Epoch: 1/20... Training loss: 0.1768\n",
      "Epoch: 1/20... Training loss: 0.1745\n",
      "Epoch: 1/20... Training loss: 0.1695\n",
      "Epoch: 1/20... Training loss: 0.1730\n",
      "Epoch: 1/20... Training loss: 0.1765\n",
      "Epoch: 1/20... Training loss: 0.1758\n",
      "Epoch: 1/20... Training loss: 0.1755\n",
      "Epoch: 1/20... Training loss: 0.1718\n",
      "Epoch: 1/20... Training loss: 0.1769\n",
      "Epoch: 1/20... Training loss: 0.1703\n",
      "Epoch: 1/20... Training loss: 0.1759\n",
      "Epoch: 1/20... Training loss: 0.1727\n",
      "Epoch: 1/20... Training loss: 0.1818\n",
      "Epoch: 1/20... Training loss: 0.1754\n",
      "Epoch: 1/20... Training loss: 0.1714\n",
      "Epoch: 1/20... Training loss: 0.1717\n",
      "Epoch: 1/20... Training loss: 0.1721\n",
      "Epoch: 1/20... Training loss: 0.1693\n",
      "Epoch: 1/20... Training loss: 0.1691\n",
      "Epoch: 1/20... Training loss: 0.1752\n",
      "Epoch: 1/20... Training loss: 0.1716\n",
      "Epoch: 1/20... Training loss: 0.1742\n",
      "Epoch: 1/20... Training loss: 0.1753\n",
      "Epoch: 1/20... Training loss: 0.1698\n",
      "Epoch: 1/20... Training loss: 0.1654\n",
      "Epoch: 1/20... Training loss: 0.1685\n",
      "Epoch: 1/20... Training loss: 0.1702\n",
      "Epoch: 1/20... Training loss: 0.1685\n",
      "Epoch: 1/20... Training loss: 0.1624\n",
      "Epoch: 1/20... Training loss: 0.1631\n",
      "Epoch: 1/20... Training loss: 0.1606\n",
      "Epoch: 1/20... Training loss: 0.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.1684\n",
      "Epoch: 1/20... Training loss: 0.1672\n",
      "Epoch: 1/20... Training loss: 0.1711\n",
      "Epoch: 1/20... Training loss: 0.1581\n",
      "Epoch: 1/20... Training loss: 0.1671\n",
      "Epoch: 1/20... Training loss: 0.1699\n",
      "Epoch: 1/20... Training loss: 0.1652\n",
      "Epoch: 1/20... Training loss: 0.1595\n",
      "Epoch: 1/20... Training loss: 0.1688\n",
      "Epoch: 1/20... Training loss: 0.1641\n",
      "Epoch: 1/20... Training loss: 0.1645\n",
      "Epoch: 1/20... Training loss: 0.1631\n",
      "Epoch: 1/20... Training loss: 0.1653\n",
      "Epoch: 1/20... Training loss: 0.1617\n",
      "Epoch: 1/20... Training loss: 0.1538\n",
      "Epoch: 1/20... Training loss: 0.1638\n",
      "Epoch: 1/20... Training loss: 0.1636\n",
      "Epoch: 1/20... Training loss: 0.1636\n",
      "Epoch: 1/20... Training loss: 0.1599\n",
      "Epoch: 1/20... Training loss: 0.1592\n",
      "Epoch: 1/20... Training loss: 0.1634\n",
      "Epoch: 1/20... Training loss: 0.1609\n",
      "Epoch: 1/20... Training loss: 0.1644\n",
      "Epoch: 1/20... Training loss: 0.1678\n",
      "Epoch: 1/20... Training loss: 0.1624\n",
      "Epoch: 1/20... Training loss: 0.1550\n",
      "Epoch: 1/20... Training loss: 0.1613\n",
      "Epoch: 1/20... Training loss: 0.1597\n",
      "Epoch: 1/20... Training loss: 0.1548\n",
      "Epoch: 1/20... Training loss: 0.1633\n",
      "Epoch: 1/20... Training loss: 0.1581\n",
      "Epoch: 1/20... Training loss: 0.1628\n",
      "Epoch: 1/20... Training loss: 0.1569\n",
      "Epoch: 1/20... Training loss: 0.1662\n",
      "Epoch: 1/20... Training loss: 0.1630\n",
      "Epoch: 1/20... Training loss: 0.1605\n",
      "Epoch: 1/20... Training loss: 0.1591\n",
      "Epoch: 1/20... Training loss: 0.1616\n",
      "Epoch: 1/20... Training loss: 0.1571\n",
      "Epoch: 1/20... Training loss: 0.1520\n",
      "Epoch: 1/20... Training loss: 0.1597\n",
      "Epoch: 1/20... Training loss: 0.1532\n",
      "Epoch: 1/20... Training loss: 0.1551\n",
      "Epoch: 1/20... Training loss: 0.1623\n",
      "Epoch: 1/20... Training loss: 0.1538\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "Epoch: 1/20... Training loss: 0.1575\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "Epoch: 1/20... Training loss: 0.1600\n",
      "Epoch: 1/20... Training loss: 0.1528\n",
      "Epoch: 1/20... Training loss: 0.1546\n",
      "Epoch: 1/20... Training loss: 0.1543\n",
      "Epoch: 1/20... Training loss: 0.1546\n",
      "Epoch: 1/20... Training loss: 0.1568\n",
      "Epoch: 1/20... Training loss: 0.1541\n",
      "Epoch: 1/20... Training loss: 0.1531\n",
      "Epoch: 1/20... Training loss: 0.1618\n",
      "Epoch: 1/20... Training loss: 0.1556\n",
      "Epoch: 1/20... Training loss: 0.1531\n",
      "Epoch: 1/20... Training loss: 0.1533\n",
      "Epoch: 1/20... Training loss: 0.1523\n",
      "Epoch: 1/20... Training loss: 0.1532\n",
      "Epoch: 1/20... Training loss: 0.1553\n",
      "Epoch: 1/20... Training loss: 0.1560\n",
      "Epoch: 1/20... Training loss: 0.1505\n",
      "Epoch: 1/20... Training loss: 0.1575\n",
      "Epoch: 1/20... Training loss: 0.1528\n",
      "Epoch: 1/20... Training loss: 0.1533\n",
      "Epoch: 1/20... Training loss: 0.1538\n",
      "Epoch: 1/20... Training loss: 0.1514\n",
      "Epoch: 1/20... Training loss: 0.1567\n",
      "Epoch: 1/20... Training loss: 0.1530\n",
      "Epoch: 1/20... Training loss: 0.1496\n",
      "Epoch: 1/20... Training loss: 0.1506\n",
      "Epoch: 1/20... Training loss: 0.1526\n",
      "Epoch: 1/20... Training loss: 0.1561\n",
      "Epoch: 1/20... Training loss: 0.1544\n",
      "Epoch: 1/20... Training loss: 0.1541\n",
      "Epoch: 2/20... Training loss: 0.1570\n",
      "Epoch: 2/20... Training loss: 0.1541\n",
      "Epoch: 2/20... Training loss: 0.1540\n",
      "Epoch: 2/20... Training loss: 0.1529\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1551\n",
      "Epoch: 2/20... Training loss: 0.1591\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1547\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1541\n",
      "Epoch: 2/20... Training loss: 0.1505\n",
      "Epoch: 2/20... Training loss: 0.1505\n",
      "Epoch: 2/20... Training loss: 0.1503\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1500\n",
      "Epoch: 2/20... Training loss: 0.1564\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1505\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1494\n",
      "Epoch: 2/20... Training loss: 0.1519\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1548\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1497\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1546\n",
      "Epoch: 2/20... Training loss: 0.1464\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1496\n",
      "Epoch: 2/20... Training loss: 0.1429\n",
      "Epoch: 2/20... Training loss: 0.1496\n",
      "Epoch: 2/20... Training loss: 0.1468\n",
      "Epoch: 2/20... Training loss: 0.1479\n",
      "Epoch: 2/20... Training loss: 0.1476\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1403\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1456\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1451\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1495\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1425\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1456\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1435\n",
      "Epoch: 2/20... Training loss: 0.1483\n",
      "Epoch: 2/20... Training loss: 0.1459\n",
      "Epoch: 2/20... Training loss: 0.1502\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1445\n",
      "Epoch: 2/20... Training loss: 0.1448\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1484\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1425\n",
      "Epoch: 2/20... Training loss: 0.1421\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1457\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1416\n",
      "Epoch: 2/20... Training loss: 0.1440\n",
      "Epoch: 2/20... Training loss: 0.1442\n",
      "Epoch: 2/20... Training loss: 0.1447\n",
      "Epoch: 2/20... Training loss: 0.1455\n",
      "Epoch: 2/20... Training loss: 0.1395\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1447\n",
      "Epoch: 2/20... Training loss: 0.1471\n",
      "Epoch: 2/20... Training loss: 0.1403\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1366\n",
      "Epoch: 2/20... Training loss: 0.1391\n",
      "Epoch: 2/20... Training loss: 0.1407\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1404\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1371\n",
      "Epoch: 2/20... Training loss: 0.1368\n",
      "Epoch: 2/20... Training loss: 0.1397\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1405\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1436\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1441\n",
      "Epoch: 2/20... Training loss: 0.1367\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1388\n",
      "Epoch: 2/20... Training loss: 0.1406\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1421\n",
      "Epoch: 2/20... Training loss: 0.1392\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1418\n",
      "Epoch: 2/20... Training loss: 0.1377\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1353\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1403\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1367\n",
      "Epoch: 2/20... Training loss: 0.1426\n",
      "Epoch: 2/20... Training loss: 0.1346\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1357\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1380\n",
      "Epoch: 2/20... Training loss: 0.1337\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1405\n",
      "Epoch: 2/20... Training loss: 0.1434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1334\n",
      "Epoch: 2/20... Training loss: 0.1330\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1438\n",
      "Epoch: 2/20... Training loss: 0.1374\n",
      "Epoch: 2/20... Training loss: 0.1352\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1359\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1433\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1388\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1374\n",
      "Epoch: 2/20... Training loss: 0.1325\n",
      "Epoch: 2/20... Training loss: 0.1391\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1402\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1363\n",
      "Epoch: 2/20... Training loss: 0.1358\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1377\n",
      "Epoch: 2/20... Training loss: 0.1392\n",
      "Epoch: 2/20... Training loss: 0.1395\n",
      "Epoch: 2/20... Training loss: 0.1326\n",
      "Epoch: 2/20... Training loss: 0.1397\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1306\n",
      "Epoch: 2/20... Training loss: 0.1363\n",
      "Epoch: 2/20... Training loss: 0.1381\n",
      "Epoch: 2/20... Training loss: 0.1358\n",
      "Epoch: 2/20... Training loss: 0.1406\n",
      "Epoch: 2/20... Training loss: 0.1386\n",
      "Epoch: 2/20... Training loss: 0.1340\n",
      "Epoch: 2/20... Training loss: 0.1350\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1314\n",
      "Epoch: 2/20... Training loss: 0.1322\n",
      "Epoch: 2/20... Training loss: 0.1343\n",
      "Epoch: 2/20... Training loss: 0.1391\n",
      "Epoch: 2/20... Training loss: 0.1358\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1395\n",
      "Epoch: 2/20... Training loss: 0.1353\n",
      "Epoch: 2/20... Training loss: 0.1346\n",
      "Epoch: 2/20... Training loss: 0.1341\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1367\n",
      "Epoch: 2/20... Training loss: 0.1373\n",
      "Epoch: 2/20... Training loss: 0.1347\n",
      "Epoch: 2/20... Training loss: 0.1332\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1348\n",
      "Epoch: 2/20... Training loss: 0.1330\n",
      "Epoch: 2/20... Training loss: 0.1337\n",
      "Epoch: 2/20... Training loss: 0.1340\n",
      "Epoch: 2/20... Training loss: 0.1365\n",
      "Epoch: 2/20... Training loss: 0.1313\n",
      "Epoch: 2/20... Training loss: 0.1375\n",
      "Epoch: 2/20... Training loss: 0.1390\n",
      "Epoch: 2/20... Training loss: 0.1299\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1344\n",
      "Epoch: 2/20... Training loss: 0.1264\n",
      "Epoch: 2/20... Training loss: 0.1367\n",
      "Epoch: 2/20... Training loss: 0.1340\n",
      "Epoch: 2/20... Training loss: 0.1375\n",
      "Epoch: 2/20... Training loss: 0.1417\n",
      "Epoch: 2/20... Training loss: 0.1309\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1319\n",
      "Epoch: 2/20... Training loss: 0.1342\n",
      "Epoch: 2/20... Training loss: 0.1334\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1310\n",
      "Epoch: 2/20... Training loss: 0.1301\n",
      "Epoch: 2/20... Training loss: 0.1334\n",
      "Epoch: 2/20... Training loss: 0.1350\n",
      "Epoch: 2/20... Training loss: 0.1354\n",
      "Epoch: 2/20... Training loss: 0.1324\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1271\n",
      "Epoch: 2/20... Training loss: 0.1359\n",
      "Epoch: 2/20... Training loss: 0.1337\n",
      "Epoch: 2/20... Training loss: 0.1326\n",
      "Epoch: 2/20... Training loss: 0.1245\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1302\n",
      "Epoch: 2/20... Training loss: 0.1308\n",
      "Epoch: 2/20... Training loss: 0.1283\n",
      "Epoch: 2/20... Training loss: 0.1327\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1305\n",
      "Epoch: 2/20... Training loss: 0.1370\n",
      "Epoch: 2/20... Training loss: 0.1306\n",
      "Epoch: 2/20... Training loss: 0.1344\n",
      "Epoch: 2/20... Training loss: 0.1346\n",
      "Epoch: 2/20... Training loss: 0.1298\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1353\n",
      "Epoch: 2/20... Training loss: 0.1378\n",
      "Epoch: 2/20... Training loss: 0.1315\n",
      "Epoch: 2/20... Training loss: 0.1299\n",
      "Epoch: 2/20... Training loss: 0.1334\n",
      "Epoch: 2/20... Training loss: 0.1376\n",
      "Epoch: 2/20... Training loss: 0.1287\n",
      "Epoch: 2/20... Training loss: 0.1358\n",
      "Epoch: 2/20... Training loss: 0.1324\n",
      "Epoch: 2/20... Training loss: 0.1265\n",
      "Epoch: 2/20... Training loss: 0.1288\n",
      "Epoch: 2/20... Training loss: 0.1301\n",
      "Epoch: 2/20... Training loss: 0.1271\n",
      "Epoch: 2/20... Training loss: 0.1310\n",
      "Epoch: 2/20... Training loss: 0.1302\n",
      "Epoch: 2/20... Training loss: 0.1347\n",
      "Epoch: 2/20... Training loss: 0.1316\n",
      "Epoch: 2/20... Training loss: 0.1305\n",
      "Epoch: 2/20... Training loss: 0.1312\n",
      "Epoch: 2/20... Training loss: 0.1416\n",
      "Epoch: 2/20... Training loss: 0.1320\n",
      "Epoch: 2/20... Training loss: 0.1289\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1323\n",
      "Epoch: 2/20... Training loss: 0.1309\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1308\n",
      "Epoch: 2/20... Training loss: 0.1317\n",
      "Epoch: 2/20... Training loss: 0.1303\n",
      "Epoch: 2/20... Training loss: 0.1339\n",
      "Epoch: 2/20... Training loss: 0.1331\n",
      "Epoch: 2/20... Training loss: 0.1249\n",
      "Epoch: 2/20... Training loss: 0.1296\n",
      "Epoch: 2/20... Training loss: 0.1331\n",
      "Epoch: 2/20... Training loss: 0.1274\n",
      "Epoch: 2/20... Training loss: 0.1309\n",
      "Epoch: 2/20... Training loss: 0.1335\n",
      "Epoch: 2/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1332\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1356\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1342\n",
      "Epoch: 3/20... Training loss: 0.1310\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1295\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1330\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1318\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1323\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1253\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1327\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1335\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1332\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1333\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1227\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1249\n",
      "Epoch: 3/20... Training loss: 0.1275\n",
      "Epoch: 3/20... Training loss: 0.1217\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1253\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1275\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1251\n",
      "Epoch: 3/20... Training loss: 0.1231\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1231\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1230\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1222\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1275\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1211\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1230\n",
      "Epoch: 3/20... Training loss: 0.1234\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1227\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1275\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1206\n",
      "Epoch: 3/20... Training loss: 0.1229\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1222\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1255\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1233\n",
      "Epoch: 3/20... Training loss: 0.1237\n",
      "Epoch: 3/20... Training loss: 0.1302\n",
      "Epoch: 3/20... Training loss: 0.1220\n",
      "Epoch: 3/20... Training loss: 0.1184\n",
      "Epoch: 3/20... Training loss: 0.1233\n",
      "Epoch: 3/20... Training loss: 0.1194\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1205\n",
      "Epoch: 3/20... Training loss: 0.1209\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1256\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1268\n",
      "Epoch: 3/20... Training loss: 0.1239\n",
      "Epoch: 3/20... Training loss: 0.1204\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1227\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1260\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1215\n",
      "Epoch: 3/20... Training loss: 0.1204\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1245\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1203\n",
      "Epoch: 3/20... Training loss: 0.1217\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1190\n",
      "Epoch: 3/20... Training loss: 0.1251\n",
      "Epoch: 3/20... Training loss: 0.1214\n",
      "Epoch: 3/20... Training loss: 0.1211\n",
      "Epoch: 3/20... Training loss: 0.1224\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1195\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1231\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1200\n",
      "Epoch: 3/20... Training loss: 0.1173\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1221\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1228\n",
      "Epoch: 3/20... Training loss: 0.1166\n",
      "Epoch: 3/20... Training loss: 0.1200\n",
      "Epoch: 3/20... Training loss: 0.1225\n",
      "Epoch: 3/20... Training loss: 0.1236\n",
      "Epoch: 3/20... Training loss: 0.1268\n",
      "Epoch: 3/20... Training loss: 0.1211\n",
      "Epoch: 3/20... Training loss: 0.1203\n",
      "Epoch: 3/20... Training loss: 0.1217\n",
      "Epoch: 3/20... Training loss: 0.1203\n",
      "Epoch: 3/20... Training loss: 0.1210\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1216\n",
      "Epoch: 3/20... Training loss: 0.1210\n",
      "Epoch: 3/20... Training loss: 0.1220\n",
      "Epoch: 3/20... Training loss: 0.1183\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1226\n",
      "Epoch: 3/20... Training loss: 0.1200\n",
      "Epoch: 3/20... Training loss: 0.1237\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1192\n",
      "Epoch: 3/20... Training loss: 0.1228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.1244\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1243\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1273\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1288\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1207\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1260\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1159\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1207\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1122\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1188\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1246\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1155\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1186\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1130\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1186\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1137\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1251\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1162\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1153\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1160\n",
      "Epoch: 4/20... Training loss: 0.1163\n",
      "Epoch: 4/20... Training loss: 0.1168\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1176\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1177\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1166\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1156\n",
      "Epoch: 4/20... Training loss: 0.1138\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 4/20... Training loss: 0.1161\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1166\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1171\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1156\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1175\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1160\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1192\n",
      "Epoch: 4/20... Training loss: 0.1167\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1143\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1186\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1150\n",
      "Epoch: 4/20... Training loss: 0.1150\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1165\n",
      "Epoch: 4/20... Training loss: 0.1145\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1139\n",
      "Epoch: 4/20... Training loss: 0.1134\n",
      "Epoch: 4/20... Training loss: 0.1138\n",
      "Epoch: 4/20... Training loss: 0.1168\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1148\n",
      "Epoch: 4/20... Training loss: 0.1167\n",
      "Epoch: 4/20... Training loss: 0.1141\n",
      "Epoch: 4/20... Training loss: 0.1134\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1178\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1148\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1164\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1168\n",
      "Epoch: 4/20... Training loss: 0.1113\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1181\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1164\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1210\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1233\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1210\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1201\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1222\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1234\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1119\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1107\n",
      "Epoch: 5/20... Training loss: 0.1117\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1128\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1209\n",
      "Epoch: 5/20... Training loss: 0.1164\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1198\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1124\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1201\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1094\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1202\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1110\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1087\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1237\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1126\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1217\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1135\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1093\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1136\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1164\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1182\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1131\n",
      "Epoch: 5/20... Training loss: 0.1122\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1108\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1198\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1100\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1104\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1115\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1086\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1193\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1190\n",
      "Epoch: 6/20... Training loss: 0.1196\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1171\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1207\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1191\n",
      "Epoch: 6/20... Training loss: 0.1092\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1174\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1230\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1190\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1187\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 6/20... Training loss: 0.1159\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1178\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1191\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1189\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1193\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1103\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1086\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1089\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1095\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1081\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1059\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1186\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1095\n",
      "Epoch: 6/20... Training loss: 0.1079\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1159\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1200\n",
      "Epoch: 7/20... Training loss: 0.1165\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1152\n",
      "Epoch: 7/20... Training loss: 0.1173\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1179\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1105\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1173\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1150\n",
      "Epoch: 7/20... Training loss: 0.1183\n",
      "Epoch: 7/20... Training loss: 0.1165\n",
      "Epoch: 7/20... Training loss: 0.1138\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1151\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1160\n",
      "Epoch: 7/20... Training loss: 0.1203\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1156\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1186\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1151\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1177\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1105\n",
      "Epoch: 7/20... Training loss: 0.1150\n",
      "Epoch: 7/20... Training loss: 0.1156\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1105\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1138\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1175\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1147\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1058\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1182\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1150\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1151\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1147\n",
      "Epoch: 7/20... Training loss: 0.1071\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1062\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1075\n",
      "Epoch: 7/20... Training loss: 0.1197\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1064\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1148\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1173\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1111\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1171\n",
      "Epoch: 7/20... Training loss: 0.1159\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1151\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1072\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1136\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1052\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1156\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1145\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1030\n",
      "Epoch: 8/20... Training loss: 0.1130\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1126\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1131\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1103\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1150\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1146\n",
      "Epoch: 8/20... Training loss: 0.1167\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1162\n",
      "Epoch: 8/20... Training loss: 0.1140\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1146\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1151\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1143\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1139\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1166\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1060\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1130\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1166\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1046\n",
      "Epoch: 8/20... Training loss: 0.1052\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1136\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1130\n",
      "Epoch: 8/20... Training loss: 0.1038\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1146\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1066\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1139\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1142\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1063\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1143\n",
      "Epoch: 8/20... Training loss: 0.1144\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1164\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1149\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1122\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1104\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1066\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1149\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1103\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1065\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1063\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1053\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1070\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1135\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1153\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1060\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1053\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1132\n",
      "Epoch: 9/20... Training loss: 0.1119\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1151\n",
      "Epoch: 9/20... Training loss: 0.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1124\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1113\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1123\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1113\n",
      "Epoch: 9/20... Training loss: 0.1053\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1090\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1090\n",
      "Epoch: 9/20... Training loss: 0.1099\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1136\n",
      "Epoch: 9/20... Training loss: 0.1123\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1028\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1113\n",
      "Epoch: 9/20... Training loss: 0.1043\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1039\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1070\n",
      "Epoch: 9/20... Training loss: 0.1110\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1054\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 9/20... Training loss: 0.1130\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1122\n",
      "Epoch: 9/20... Training loss: 0.1123\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1038\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1027\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.0971\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1090\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1131\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1116\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1037\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1125\n",
      "Epoch: 9/20... Training loss: 0.1133\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1033\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1134\n",
      "Epoch: 9/20... Training loss: 0.1050\n",
      "Epoch: 9/20... Training loss: 0.1043\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1119\n",
      "Epoch: 9/20... Training loss: 0.1110\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1123\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1114\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1106\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1110\n",
      "Epoch: 10/20... Training loss: 0.1124\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1114\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1017\n",
      "Epoch: 10/20... Training loss: 0.1115\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1112\n",
      "Epoch: 10/20... Training loss: 0.1100\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1138\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1137\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1119\n",
      "Epoch: 10/20... Training loss: 0.1129\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1039\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1140\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1020\n",
      "Epoch: 10/20... Training loss: 0.1119\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1102\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1118\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1026\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1100\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1024\n",
      "Epoch: 10/20... Training loss: 0.1132\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1113\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1122\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1114\n",
      "Epoch: 10/20... Training loss: 0.1027\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1119\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1037\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1105\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1114\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1076\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1111\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1086\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1111\n",
      "Epoch: 11/20... Training loss: 0.1093\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1074\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1025\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1112\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1118\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1111\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1105\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1098\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1027\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1101\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1010\n",
      "Epoch: 11/20... Training loss: 0.1023\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1093\n",
      "Epoch: 11/20... Training loss: 0.1038\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1111\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1036\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1103\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1096\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1119\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1144\n",
      "Epoch: 11/20... Training loss: 0.0995\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1074\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1086\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1101\n",
      "Epoch: 11/20... Training loss: 0.1076\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.0988\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1108\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1106\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1017\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1030\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1018\n",
      "Epoch: 12/20... Training loss: 0.1114\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1006\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1107\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1084\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1095\n",
      "Epoch: 12/20... Training loss: 0.1110\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.0991\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1008\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1097\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1111\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.0993\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1097\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1111\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1013\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1089\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.0998\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1114\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.0983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.0985\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.0958\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1002\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1092\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1111\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1089\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1075\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1098\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1100\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.0988\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1087\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.1091\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1083\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1084\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.0991\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20... Training loss: 0.1081\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1104\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1086\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.0994\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.0985\n",
      "Epoch: 13/20... Training loss: 0.1098\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1080\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1078\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.0982\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.0988\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.0989\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1102\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1043\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.1078\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.0972\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1080\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1015\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.0997\n",
      "Epoch: 14/20... Training loss: 0.1065\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1015\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1067\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1082\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.0993\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1082\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1003\n",
      "Epoch: 14/20... Training loss: 0.1083\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1000\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.0961\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1074\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1104\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1029\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1029\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1079\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 15/20... Training loss: 0.1073\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1067\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1061\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.0994\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1054\n",
      "Epoch: 15/20... Training loss: 0.0987\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.0964\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1054\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1067\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1081\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.0980\n",
      "Epoch: 15/20... Training loss: 0.1078\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.0987\n",
      "Epoch: 15/20... Training loss: 0.0966\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.0975\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1090\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.0991\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.0973\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.0989\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1061\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1082\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0988\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1079\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0967\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1049\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1061\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.0952\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0991\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1071\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1013\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.0980\n",
      "Epoch: 16/20... Training loss: 0.1058\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1059\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0975\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1088\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1053\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1039\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1061\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1053\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.0947\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1077\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1039\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0984\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.1058\n",
      "Epoch: 16/20... Training loss: 0.0986\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1049\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1053\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.0988\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.0993\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1062\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.0983\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1062\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.0987\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0958\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.0969\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.0983\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.1056\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1055\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.0967\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.0932\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1052\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1036\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.0980\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0974\n",
      "Epoch: 17/20... Training loss: 0.1063\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.0953\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1056\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1055\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1070\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1041\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.0975\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1050\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0965\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.0972\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1053\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.0955\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0976\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1055\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.0964\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.0936\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1053\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.0966\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.0962\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.0953\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.0949\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0926\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.0978\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0957\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.1047\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.0963\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1024\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.1044\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.0972\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.1032\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1068\n",
      "Epoch: 19/20... Training loss: 0.0963\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.1042\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.1032\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1026\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1036\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.1044\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.1050\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0966\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.0993\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0993\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1035\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0934\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.0950\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1035\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.0947\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1041\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1053\n",
      "Epoch: 19/20... Training loss: 0.0993\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0952\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0961\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.0933\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.0965\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0978\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.0956\n",
      "Epoch: 19/20... Training loss: 0.0949\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.0968\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.0959\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.1048\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.1039\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1038\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.1065\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1036\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.1040\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1030\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.1037\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0926\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.0948\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.0959\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1030\n",
      "Epoch: 20/20... Training loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20... Training loss: 0.1036\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0960\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.1044\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0955\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0942\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0947\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0956\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.0932\n",
      "Epoch: 20/20... Training loss: 0.1030\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0962\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1044\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0944\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1040\n",
      "Epoch: 20/20... Training loss: 0.0933\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0958\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.0957\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.0951\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.0964\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.0940\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising\n",
    "\n",
    "As I've mentioned before, autoencoders like the ones you've built so far aren't too useful in practive. However, they can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1. We'll use noisy images as input and the original, clean images as targets. Here's an example of the noisy images I generated and the denoised images.\n",
    "\n",
    "![Denoising autoencoder](assets/denoising.png)\n",
    "\n",
    "\n",
    "Since this is a harder problem for the network, we'll want to use deeper convolutional layers here, more feature maps. I suggest something like 32-32-16 for the depths of the convolutional layers in the encoder, and the same depths going backward through the decoder. Otherwise the architecture is the same as before.\n",
    "\n",
    "> **Exercise:** Build the network for the denoising autoencoder. It's the same as before, but with deeper layers. I suggest 32-32-16 for the depths, but you can play with these numbers, or add more layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CE9E888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CE9E888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CE9E888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CE9E888>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E8DE188>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E8DE188>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E8DE188>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E8DE188>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8DEF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8DEF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8DEF88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E8DEF88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF9CC90DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF9CC90DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF9CC90DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF9CC90DC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001B085F51648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001B085F51648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001B085F51648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001B085F51648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E86D988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E86D988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E86D988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001AF8E86D988>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CC8BF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CC8BF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CC8BF48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF9CC8BF48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8E87CD08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8EA4F288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8EA4F288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8EA4F288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001AF8EA4F288>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "# Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "# Now 14x14x32\n",
    "conv2 = tf.layers.conv2d(maxpool1, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "# Now 7x7x32\n",
    "conv3 = tf.layers.conv2d(maxpool2, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "# Now 4x4x16\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "# Now 7x7x16\n",
    "conv4 = tf.layers.conv2d(upsample1, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 7x7x16\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "# Now 14x14x16\n",
    "conv5 = tf.layers.conv2d(upsample2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 14x14x32\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "# Now 28x28x32\n",
    "conv6 = tf.layers.conv2d(upsample3, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "# Now 28x28x32\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "#Now 28x28x1\n",
    "\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.6957\n",
      "Epoch: 1/100... Training loss: 0.6765\n",
      "Epoch: 1/100... Training loss: 0.6541\n",
      "Epoch: 1/100... Training loss: 0.6230\n",
      "Epoch: 1/100... Training loss: 0.5835\n",
      "Epoch: 1/100... Training loss: 0.5366\n",
      "Epoch: 1/100... Training loss: 0.4879\n",
      "Epoch: 1/100... Training loss: 0.4855\n",
      "Epoch: 1/100... Training loss: 0.5123\n",
      "Epoch: 1/100... Training loss: 0.4993\n",
      "Epoch: 1/100... Training loss: 0.4892\n",
      "Epoch: 1/100... Training loss: 0.4639\n",
      "Epoch: 1/100... Training loss: 0.4383\n",
      "Epoch: 1/100... Training loss: 0.4373\n",
      "Epoch: 1/100... Training loss: 0.4362\n",
      "Epoch: 1/100... Training loss: 0.4266\n",
      "Epoch: 1/100... Training loss: 0.4237\n",
      "Epoch: 1/100... Training loss: 0.4104\n",
      "Epoch: 1/100... Training loss: 0.3958\n",
      "Epoch: 1/100... Training loss: 0.3905\n",
      "Epoch: 1/100... Training loss: 0.3665\n",
      "Epoch: 1/100... Training loss: 0.3612\n",
      "Epoch: 1/100... Training loss: 0.3462\n",
      "Epoch: 1/100... Training loss: 0.3309\n",
      "Epoch: 1/100... Training loss: 0.3204\n",
      "Epoch: 1/100... Training loss: 0.3073\n",
      "Epoch: 1/100... Training loss: 0.2989\n",
      "Epoch: 1/100... Training loss: 0.2988\n",
      "Epoch: 1/100... Training loss: 0.2783\n",
      "Epoch: 1/100... Training loss: 0.2856\n",
      "Epoch: 1/100... Training loss: 0.2739\n",
      "Epoch: 1/100... Training loss: 0.2715\n",
      "Epoch: 1/100... Training loss: 0.2670\n",
      "Epoch: 1/100... Training loss: 0.2676\n",
      "Epoch: 1/100... Training loss: 0.2677\n",
      "Epoch: 1/100... Training loss: 0.2634\n",
      "Epoch: 1/100... Training loss: 0.2682\n",
      "Epoch: 1/100... Training loss: 0.2571\n",
      "Epoch: 1/100... Training loss: 0.2553\n",
      "Epoch: 1/100... Training loss: 0.2573\n",
      "Epoch: 1/100... Training loss: 0.2553\n",
      "Epoch: 1/100... Training loss: 0.2525\n",
      "Epoch: 1/100... Training loss: 0.2593\n",
      "Epoch: 1/100... Training loss: 0.2586\n",
      "Epoch: 1/100... Training loss: 0.2570\n",
      "Epoch: 1/100... Training loss: 0.2477\n",
      "Epoch: 1/100... Training loss: 0.2492\n",
      "Epoch: 1/100... Training loss: 0.2437\n",
      "Epoch: 1/100... Training loss: 0.2492\n",
      "Epoch: 1/100... Training loss: 0.2501\n",
      "Epoch: 1/100... Training loss: 0.2327\n",
      "Epoch: 1/100... Training loss: 0.2395\n",
      "Epoch: 1/100... Training loss: 0.2431\n",
      "Epoch: 1/100... Training loss: 0.2400\n",
      "Epoch: 1/100... Training loss: 0.2352\n",
      "Epoch: 1/100... Training loss: 0.2376\n",
      "Epoch: 1/100... Training loss: 0.2418\n",
      "Epoch: 1/100... Training loss: 0.2304\n",
      "Epoch: 1/100... Training loss: 0.2328\n",
      "Epoch: 1/100... Training loss: 0.2370\n",
      "Epoch: 1/100... Training loss: 0.2349\n",
      "Epoch: 1/100... Training loss: 0.2255\n",
      "Epoch: 1/100... Training loss: 0.2295\n",
      "Epoch: 1/100... Training loss: 0.2273\n",
      "Epoch: 1/100... Training loss: 0.2318\n",
      "Epoch: 1/100... Training loss: 0.2371\n",
      "Epoch: 1/100... Training loss: 0.2226\n",
      "Epoch: 1/100... Training loss: 0.2394\n",
      "Epoch: 1/100... Training loss: 0.2352\n",
      "Epoch: 1/100... Training loss: 0.2368\n",
      "Epoch: 1/100... Training loss: 0.2213\n",
      "Epoch: 1/100... Training loss: 0.2479\n",
      "Epoch: 1/100... Training loss: 0.2158\n",
      "Epoch: 1/100... Training loss: 0.2357\n",
      "Epoch: 1/100... Training loss: 0.2281\n",
      "Epoch: 1/100... Training loss: 0.2273\n",
      "Epoch: 1/100... Training loss: 0.2376\n",
      "Epoch: 1/100... Training loss: 0.2281\n",
      "Epoch: 1/100... Training loss: 0.2278\n",
      "Epoch: 1/100... Training loss: 0.2195\n",
      "Epoch: 1/100... Training loss: 0.2269\n",
      "Epoch: 1/100... Training loss: 0.2245\n",
      "Epoch: 1/100... Training loss: 0.2160\n",
      "Epoch: 1/100... Training loss: 0.2241\n",
      "Epoch: 1/100... Training loss: 0.2290\n",
      "Epoch: 1/100... Training loss: 0.2186\n",
      "Epoch: 1/100... Training loss: 0.2275\n",
      "Epoch: 1/100... Training loss: 0.2179\n",
      "Epoch: 1/100... Training loss: 0.2242\n",
      "Epoch: 1/100... Training loss: 0.2158\n",
      "Epoch: 1/100... Training loss: 0.2223\n",
      "Epoch: 1/100... Training loss: 0.2199\n",
      "Epoch: 1/100... Training loss: 0.2184\n",
      "Epoch: 1/100... Training loss: 0.2182\n",
      "Epoch: 1/100... Training loss: 0.2237\n",
      "Epoch: 1/100... Training loss: 0.2245\n",
      "Epoch: 1/100... Training loss: 0.2156\n",
      "Epoch: 1/100... Training loss: 0.2142\n",
      "Epoch: 1/100... Training loss: 0.2176\n",
      "Epoch: 1/100... Training loss: 0.2125\n",
      "Epoch: 1/100... Training loss: 0.2185\n",
      "Epoch: 1/100... Training loss: 0.2142\n",
      "Epoch: 1/100... Training loss: 0.2079\n",
      "Epoch: 1/100... Training loss: 0.2156\n",
      "Epoch: 1/100... Training loss: 0.2163\n",
      "Epoch: 1/100... Training loss: 0.2154\n",
      "Epoch: 1/100... Training loss: 0.2159\n",
      "Epoch: 1/100... Training loss: 0.2129\n",
      "Epoch: 1/100... Training loss: 0.2104\n",
      "Epoch: 1/100... Training loss: 0.2107\n",
      "Epoch: 1/100... Training loss: 0.2089\n",
      "Epoch: 1/100... Training loss: 0.2172\n",
      "Epoch: 1/100... Training loss: 0.2064\n",
      "Epoch: 1/100... Training loss: 0.2073\n",
      "Epoch: 1/100... Training loss: 0.2116\n",
      "Epoch: 1/100... Training loss: 0.2056\n",
      "Epoch: 1/100... Training loss: 0.2092\n",
      "Epoch: 1/100... Training loss: 0.2091\n",
      "Epoch: 1/100... Training loss: 0.2099\n",
      "Epoch: 1/100... Training loss: 0.2051\n",
      "Epoch: 1/100... Training loss: 0.2085\n",
      "Epoch: 1/100... Training loss: 0.2087\n",
      "Epoch: 1/100... Training loss: 0.2077\n",
      "Epoch: 1/100... Training loss: 0.2050\n",
      "Epoch: 1/100... Training loss: 0.2090\n",
      "Epoch: 1/100... Training loss: 0.2068\n",
      "Epoch: 1/100... Training loss: 0.2088\n",
      "Epoch: 1/100... Training loss: 0.2017\n",
      "Epoch: 1/100... Training loss: 0.2053\n",
      "Epoch: 1/100... Training loss: 0.2036\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.2029\n",
      "Epoch: 1/100... Training loss: 0.2031\n",
      "Epoch: 1/100... Training loss: 0.2048\n",
      "Epoch: 1/100... Training loss: 0.2018\n",
      "Epoch: 1/100... Training loss: 0.1987\n",
      "Epoch: 1/100... Training loss: 0.2023\n",
      "Epoch: 1/100... Training loss: 0.2004\n",
      "Epoch: 1/100... Training loss: 0.1967\n",
      "Epoch: 1/100... Training loss: 0.1979\n",
      "Epoch: 1/100... Training loss: 0.1949\n",
      "Epoch: 1/100... Training loss: 0.1985\n",
      "Epoch: 1/100... Training loss: 0.1983\n",
      "Epoch: 1/100... Training loss: 0.1945\n",
      "Epoch: 1/100... Training loss: 0.1956\n",
      "Epoch: 1/100... Training loss: 0.1933\n",
      "Epoch: 1/100... Training loss: 0.1938\n",
      "Epoch: 1/100... Training loss: 0.1908\n",
      "Epoch: 1/100... Training loss: 0.1929\n",
      "Epoch: 1/100... Training loss: 0.1967\n",
      "Epoch: 1/100... Training loss: 0.1960\n",
      "Epoch: 1/100... Training loss: 0.1950\n",
      "Epoch: 1/100... Training loss: 0.1882\n",
      "Epoch: 1/100... Training loss: 0.1944\n",
      "Epoch: 1/100... Training loss: 0.1929\n",
      "Epoch: 1/100... Training loss: 0.1875\n",
      "Epoch: 1/100... Training loss: 0.1910\n",
      "Epoch: 1/100... Training loss: 0.1907\n",
      "Epoch: 1/100... Training loss: 0.1888\n",
      "Epoch: 1/100... Training loss: 0.1913\n",
      "Epoch: 1/100... Training loss: 0.1921\n",
      "Epoch: 1/100... Training loss: 0.1864\n",
      "Epoch: 1/100... Training loss: 0.1871\n",
      "Epoch: 1/100... Training loss: 0.1896\n",
      "Epoch: 1/100... Training loss: 0.1882\n",
      "Epoch: 1/100... Training loss: 0.1931\n",
      "Epoch: 1/100... Training loss: 0.1871\n",
      "Epoch: 1/100... Training loss: 0.1863\n",
      "Epoch: 1/100... Training loss: 0.1924\n",
      "Epoch: 1/100... Training loss: 0.1896\n",
      "Epoch: 1/100... Training loss: 0.1889\n",
      "Epoch: 1/100... Training loss: 0.1862\n",
      "Epoch: 1/100... Training loss: 0.1820\n",
      "Epoch: 1/100... Training loss: 0.1860\n",
      "Epoch: 1/100... Training loss: 0.1870\n",
      "Epoch: 1/100... Training loss: 0.1802\n",
      "Epoch: 1/100... Training loss: 0.1817\n",
      "Epoch: 1/100... Training loss: 0.1811\n",
      "Epoch: 1/100... Training loss: 0.1863\n",
      "Epoch: 1/100... Training loss: 0.1846\n",
      "Epoch: 1/100... Training loss: 0.1863\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1831\n",
      "Epoch: 1/100... Training loss: 0.1795\n",
      "Epoch: 1/100... Training loss: 0.1874\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1831\n",
      "Epoch: 1/100... Training loss: 0.1844\n",
      "Epoch: 1/100... Training loss: 0.1806\n",
      "Epoch: 1/100... Training loss: 0.1791\n",
      "Epoch: 1/100... Training loss: 0.1794\n",
      "Epoch: 1/100... Training loss: 0.1788\n",
      "Epoch: 1/100... Training loss: 0.1763\n",
      "Epoch: 1/100... Training loss: 0.1772\n",
      "Epoch: 1/100... Training loss: 0.1783\n",
      "Epoch: 1/100... Training loss: 0.1761\n",
      "Epoch: 1/100... Training loss: 0.1837\n",
      "Epoch: 1/100... Training loss: 0.1818\n",
      "Epoch: 1/100... Training loss: 0.1798\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1721\n",
      "Epoch: 1/100... Training loss: 0.1731\n",
      "Epoch: 1/100... Training loss: 0.1810\n",
      "Epoch: 1/100... Training loss: 0.1810\n",
      "Epoch: 1/100... Training loss: 0.1751\n",
      "Epoch: 1/100... Training loss: 0.1740\n",
      "Epoch: 1/100... Training loss: 0.1816\n",
      "Epoch: 1/100... Training loss: 0.1817\n",
      "Epoch: 1/100... Training loss: 0.1762\n",
      "Epoch: 1/100... Training loss: 0.1753\n",
      "Epoch: 1/100... Training loss: 0.1756\n",
      "Epoch: 1/100... Training loss: 0.1735\n",
      "Epoch: 1/100... Training loss: 0.1786\n",
      "Epoch: 1/100... Training loss: 0.1799\n",
      "Epoch: 1/100... Training loss: 0.1722\n",
      "Epoch: 1/100... Training loss: 0.1747\n",
      "Epoch: 1/100... Training loss: 0.1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.1674\n",
      "Epoch: 1/100... Training loss: 0.1765\n",
      "Epoch: 1/100... Training loss: 0.1763\n",
      "Epoch: 1/100... Training loss: 0.1759\n",
      "Epoch: 1/100... Training loss: 0.1735\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1720\n",
      "Epoch: 1/100... Training loss: 0.1749\n",
      "Epoch: 1/100... Training loss: 0.1720\n",
      "Epoch: 1/100... Training loss: 0.1794\n",
      "Epoch: 1/100... Training loss: 0.1723\n",
      "Epoch: 1/100... Training loss: 0.1786\n",
      "Epoch: 1/100... Training loss: 0.1795\n",
      "Epoch: 1/100... Training loss: 0.1749\n",
      "Epoch: 1/100... Training loss: 0.1709\n",
      "Epoch: 1/100... Training loss: 0.1695\n",
      "Epoch: 1/100... Training loss: 0.1728\n",
      "Epoch: 1/100... Training loss: 0.1688\n",
      "Epoch: 1/100... Training loss: 0.1705\n",
      "Epoch: 1/100... Training loss: 0.1683\n",
      "Epoch: 1/100... Training loss: 0.1677\n",
      "Epoch: 1/100... Training loss: 0.1754\n",
      "Epoch: 1/100... Training loss: 0.1737\n",
      "Epoch: 1/100... Training loss: 0.1693\n",
      "Epoch: 1/100... Training loss: 0.1686\n",
      "Epoch: 1/100... Training loss: 0.1742\n",
      "Epoch: 1/100... Training loss: 0.1674\n",
      "Epoch: 1/100... Training loss: 0.1682\n",
      "Epoch: 1/100... Training loss: 0.1723\n",
      "Epoch: 1/100... Training loss: 0.1702\n",
      "Epoch: 1/100... Training loss: 0.1740\n",
      "Epoch: 1/100... Training loss: 0.1740\n",
      "Epoch: 1/100... Training loss: 0.1688\n",
      "Epoch: 1/100... Training loss: 0.1686\n",
      "Epoch: 1/100... Training loss: 0.1709\n",
      "Epoch: 1/100... Training loss: 0.1670\n",
      "Epoch: 1/100... Training loss: 0.1722\n",
      "Epoch: 1/100... Training loss: 0.1775\n",
      "Epoch: 1/100... Training loss: 0.1728\n",
      "Epoch: 1/100... Training loss: 0.1727\n",
      "Epoch: 1/100... Training loss: 0.1752\n",
      "Epoch: 1/100... Training loss: 0.1664\n",
      "Epoch: 1/100... Training loss: 0.1667\n",
      "Epoch: 1/100... Training loss: 0.1681\n",
      "Epoch: 1/100... Training loss: 0.1653\n",
      "Epoch: 1/100... Training loss: 0.1720\n",
      "Epoch: 1/100... Training loss: 0.1700\n",
      "Epoch: 1/100... Training loss: 0.1658\n",
      "Epoch: 1/100... Training loss: 0.1676\n",
      "Epoch: 1/100... Training loss: 0.1737\n",
      "Epoch: 1/100... Training loss: 0.1709\n",
      "Epoch: 1/100... Training loss: 0.1653\n",
      "Epoch: 1/100... Training loss: 0.1694\n",
      "Epoch: 1/100... Training loss: 0.1662\n",
      "Epoch: 1/100... Training loss: 0.1692\n",
      "Epoch: 1/100... Training loss: 0.1700\n",
      "Epoch: 1/100... Training loss: 0.1628\n",
      "Epoch: 1/100... Training loss: 0.1693\n",
      "Epoch: 1/100... Training loss: 0.1734\n",
      "Epoch: 1/100... Training loss: 0.1691\n",
      "Epoch: 1/100... Training loss: 0.1713\n",
      "Epoch: 1/100... Training loss: 0.1745\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1661\n",
      "Epoch: 1/100... Training loss: 0.1647\n",
      "Epoch: 1/100... Training loss: 0.1665\n",
      "Epoch: 1/100... Training loss: 0.1678\n",
      "Epoch: 1/100... Training loss: 0.1651\n",
      "Epoch: 1/100... Training loss: 0.1676\n",
      "Epoch: 1/100... Training loss: 0.1669\n",
      "Epoch: 1/100... Training loss: 0.1721\n",
      "Epoch: 1/100... Training loss: 0.1701\n",
      "Epoch: 1/100... Training loss: 0.1757\n",
      "Epoch: 1/100... Training loss: 0.1667\n",
      "Epoch: 1/100... Training loss: 0.1669\n",
      "Epoch: 1/100... Training loss: 0.1664\n",
      "Epoch: 1/100... Training loss: 0.1680\n",
      "Epoch: 1/100... Training loss: 0.1651\n",
      "Epoch: 1/100... Training loss: 0.1672\n",
      "Epoch: 1/100... Training loss: 0.1663\n",
      "Epoch: 1/100... Training loss: 0.1659\n",
      "Epoch: 1/100... Training loss: 0.1629\n",
      "Epoch: 1/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1740\n",
      "Epoch: 2/100... Training loss: 0.1627\n",
      "Epoch: 2/100... Training loss: 0.1631\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1683\n",
      "Epoch: 2/100... Training loss: 0.1666\n",
      "Epoch: 2/100... Training loss: 0.1657\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1684\n",
      "Epoch: 2/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1663\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1631\n",
      "Epoch: 2/100... Training loss: 0.1682\n",
      "Epoch: 2/100... Training loss: 0.1679\n",
      "Epoch: 2/100... Training loss: 0.1640\n",
      "Epoch: 2/100... Training loss: 0.1646\n",
      "Epoch: 2/100... Training loss: 0.1629\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1608\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 2/100... Training loss: 0.1679\n",
      "Epoch: 2/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1632\n",
      "Epoch: 2/100... Training loss: 0.1626\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1680\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1678\n",
      "Epoch: 2/100... Training loss: 0.1628\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1638\n",
      "Epoch: 2/100... Training loss: 0.1676\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1590\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1580\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1659\n",
      "Epoch: 2/100... Training loss: 0.1604\n",
      "Epoch: 2/100... Training loss: 0.1627\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 2/100... Training loss: 0.1622\n",
      "Epoch: 2/100... Training loss: 0.1584\n",
      "Epoch: 2/100... Training loss: 0.1630\n",
      "Epoch: 2/100... Training loss: 0.1643\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1630\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1593\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1648\n",
      "Epoch: 2/100... Training loss: 0.1551\n",
      "Epoch: 2/100... Training loss: 0.1662\n",
      "Epoch: 2/100... Training loss: 0.1583\n",
      "Epoch: 2/100... Training loss: 0.1629\n",
      "Epoch: 2/100... Training loss: 0.1590\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1585\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1592\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1600\n",
      "Epoch: 2/100... Training loss: 0.1625\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1555\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1540\n",
      "Epoch: 2/100... Training loss: 0.1614\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 2/100... Training loss: 0.1585\n",
      "Epoch: 2/100... Training loss: 0.1659\n",
      "Epoch: 2/100... Training loss: 0.1616\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1554\n",
      "Epoch: 2/100... Training loss: 0.1622\n",
      "Epoch: 2/100... Training loss: 0.1591\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1603\n",
      "Epoch: 2/100... Training loss: 0.1555\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1592\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1503\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1506\n",
      "Epoch: 2/100... Training loss: 0.1559\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1596\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1616\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1521\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1523\n",
      "Epoch: 2/100... Training loss: 0.1499\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1551\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1583\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100... Training loss: 0.1516\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1555\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1527\n",
      "Epoch: 2/100... Training loss: 0.1483\n",
      "Epoch: 2/100... Training loss: 0.1575\n",
      "Epoch: 2/100... Training loss: 0.1521\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1583\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1533\n",
      "Epoch: 2/100... Training loss: 0.1544\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1513\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1501\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1547\n",
      "Epoch: 2/100... Training loss: 0.1508\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1583\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1506\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1503\n",
      "Epoch: 2/100... Training loss: 0.1482\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1529\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1517\n",
      "Epoch: 2/100... Training loss: 0.1532\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1527\n",
      "Epoch: 2/100... Training loss: 0.1510\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 2/100... Training loss: 0.1497\n",
      "Epoch: 2/100... Training loss: 0.1492\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1502\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1551\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1460\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1526\n",
      "Epoch: 2/100... Training loss: 0.1482\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1511\n",
      "Epoch: 2/100... Training loss: 0.1505\n",
      "Epoch: 2/100... Training loss: 0.1446\n",
      "Epoch: 2/100... Training loss: 0.1538\n",
      "Epoch: 2/100... Training loss: 0.1534\n",
      "Epoch: 2/100... Training loss: 0.1503\n",
      "Epoch: 2/100... Training loss: 0.1512\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1458\n",
      "Epoch: 2/100... Training loss: 0.1500\n",
      "Epoch: 2/100... Training loss: 0.1464\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1499\n",
      "Epoch: 2/100... Training loss: 0.1504\n",
      "Epoch: 2/100... Training loss: 0.1517\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1494\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1521\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1524\n",
      "Epoch: 2/100... Training loss: 0.1463\n",
      "Epoch: 2/100... Training loss: 0.1444\n",
      "Epoch: 2/100... Training loss: 0.1506\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1469\n",
      "Epoch: 2/100... Training loss: 0.1448\n",
      "Epoch: 2/100... Training loss: 0.1477\n",
      "Epoch: 2/100... Training loss: 0.1430\n",
      "Epoch: 2/100... Training loss: 0.1506\n",
      "Epoch: 2/100... Training loss: 0.1436\n",
      "Epoch: 2/100... Training loss: 0.1491\n",
      "Epoch: 2/100... Training loss: 0.1450\n",
      "Epoch: 2/100... Training loss: 0.1426\n",
      "Epoch: 2/100... Training loss: 0.1484\n",
      "Epoch: 2/100... Training loss: 0.1498\n",
      "Epoch: 2/100... Training loss: 0.1426\n",
      "Epoch: 2/100... Training loss: 0.1478\n",
      "Epoch: 2/100... Training loss: 0.1487\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1428\n",
      "Epoch: 2/100... Training loss: 0.1462\n",
      "Epoch: 2/100... Training loss: 0.1515\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1438\n",
      "Epoch: 2/100... Training loss: 0.1433\n",
      "Epoch: 2/100... Training loss: 0.1450\n",
      "Epoch: 2/100... Training loss: 0.1451\n",
      "Epoch: 2/100... Training loss: 0.1442\n",
      "Epoch: 2/100... Training loss: 0.1480\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1465\n",
      "Epoch: 2/100... Training loss: 0.1461\n",
      "Epoch: 2/100... Training loss: 0.1415\n",
      "Epoch: 2/100... Training loss: 0.1457\n",
      "Epoch: 2/100... Training loss: 0.1476\n",
      "Epoch: 2/100... Training loss: 0.1377\n",
      "Epoch: 2/100... Training loss: 0.1424\n",
      "Epoch: 2/100... Training loss: 0.1440\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1441\n",
      "Epoch: 2/100... Training loss: 0.1475\n",
      "Epoch: 2/100... Training loss: 0.1472\n",
      "Epoch: 2/100... Training loss: 0.1425\n",
      "Epoch: 2/100... Training loss: 0.1410\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1402\n",
      "Epoch: 2/100... Training loss: 0.1447\n",
      "Epoch: 2/100... Training loss: 0.1449\n",
      "Epoch: 2/100... Training loss: 0.1445\n",
      "Epoch: 2/100... Training loss: 0.1416\n",
      "Epoch: 2/100... Training loss: 0.1455\n",
      "Epoch: 2/100... Training loss: 0.1430\n",
      "Epoch: 2/100... Training loss: 0.1442\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1432\n",
      "Epoch: 2/100... Training loss: 0.1456\n",
      "Epoch: 2/100... Training loss: 0.1422\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1474\n",
      "Epoch: 2/100... Training loss: 0.1453\n",
      "Epoch: 2/100... Training loss: 0.1495\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1466\n",
      "Epoch: 2/100... Training loss: 0.1470\n",
      "Epoch: 2/100... Training loss: 0.1467\n",
      "Epoch: 2/100... Training loss: 0.1435\n",
      "Epoch: 2/100... Training loss: 0.1458\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1477\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1452\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1446\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1471\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1407\n",
      "Epoch: 3/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1454\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1422\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1494\n",
      "Epoch: 3/100... Training loss: 0.1443\n",
      "Epoch: 3/100... Training loss: 0.1472\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1455\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1418\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1443\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1474\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1442\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1418\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1493\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1473\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1496\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1401\n",
      "Epoch: 3/100... Training loss: 0.1449\n",
      "Epoch: 3/100... Training loss: 0.1407\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1394\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1438\n",
      "Epoch: 3/100... Training loss: 0.1415\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1449\n",
      "Epoch: 3/100... Training loss: 0.1401\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1446\n",
      "Epoch: 3/100... Training loss: 0.1409\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1404\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1450\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1409\n",
      "Epoch: 3/100... Training loss: 0.1421\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1418\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1391\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1403\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1440\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1421\n",
      "Epoch: 3/100... Training loss: 0.1407\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1362\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1400\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1382\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1406\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1393\n",
      "Epoch: 3/100... Training loss: 0.1359\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1408\n",
      "Epoch: 3/100... Training loss: 0.1401\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1338\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1375\n",
      "Epoch: 3/100... Training loss: 0.1371\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1401\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1342\n",
      "Epoch: 3/100... Training loss: 0.1309\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1379\n",
      "Epoch: 3/100... Training loss: 0.1354\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1377\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1351\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1331\n",
      "Epoch: 3/100... Training loss: 0.1380\n",
      "Epoch: 3/100... Training loss: 0.1388\n",
      "Epoch: 3/100... Training loss: 0.1399\n",
      "Epoch: 3/100... Training loss: 0.1387\n",
      "Epoch: 3/100... Training loss: 0.1328\n",
      "Epoch: 3/100... Training loss: 0.1322\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1370\n",
      "Epoch: 3/100... Training loss: 0.1314\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1363\n",
      "Epoch: 3/100... Training loss: 0.1376\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1295\n",
      "Epoch: 3/100... Training loss: 0.1419\n",
      "Epoch: 3/100... Training loss: 0.1358\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1308\n",
      "Epoch: 3/100... Training loss: 0.1381\n",
      "Epoch: 3/100... Training loss: 0.1352\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1345\n",
      "Epoch: 3/100... Training loss: 0.1392\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1328\n",
      "Epoch: 3/100... Training loss: 0.1353\n",
      "Epoch: 3/100... Training loss: 0.1365\n",
      "Epoch: 3/100... Training loss: 0.1333\n",
      "Epoch: 3/100... Training loss: 0.1349\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1357\n",
      "Epoch: 3/100... Training loss: 0.1385\n",
      "Epoch: 3/100... Training loss: 0.1390\n",
      "Epoch: 3/100... Training loss: 0.1329\n",
      "Epoch: 3/100... Training loss: 0.1326\n",
      "Epoch: 3/100... Training loss: 0.1337\n",
      "Epoch: 3/100... Training loss: 0.1360\n",
      "Epoch: 3/100... Training loss: 0.1350\n",
      "Epoch: 3/100... Training loss: 0.1321\n",
      "Epoch: 3/100... Training loss: 0.1364\n",
      "Epoch: 3/100... Training loss: 0.1361\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1346\n",
      "Epoch: 3/100... Training loss: 0.1335\n",
      "Epoch: 3/100... Training loss: 0.1368\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1367\n",
      "Epoch: 3/100... Training loss: 0.1318\n",
      "Epoch: 3/100... Training loss: 0.1347\n",
      "Epoch: 3/100... Training loss: 0.1320\n",
      "Epoch: 3/100... Training loss: 0.1378\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1330\n",
      "Epoch: 3/100... Training loss: 0.1309\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1372\n",
      "Epoch: 3/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1417\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1354\n",
      "Epoch: 4/100... Training loss: 0.1370\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1388\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1366\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1383\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1370\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1374\n",
      "Epoch: 4/100... Training loss: 0.1370\n",
      "Epoch: 4/100... Training loss: 0.1369\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1352\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1389\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1368\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1312\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1368\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1313\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1361\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1387\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1302\n",
      "Epoch: 4/100... Training loss: 0.1352\n",
      "Epoch: 4/100... Training loss: 0.1270\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1252\n",
      "Epoch: 4/100... Training loss: 0.1381\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1358\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1272\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1271\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 4/100... Training loss: 0.1351\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1262\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1262\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1350\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1304\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1240\n",
      "Epoch: 4/100... Training loss: 0.1337\n",
      "Epoch: 4/100... Training loss: 0.1266\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1273\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1294\n",
      "Epoch: 4/100... Training loss: 0.1251\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1257\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1297\n",
      "Epoch: 4/100... Training loss: 0.1318\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1262\n",
      "Epoch: 4/100... Training loss: 0.1305\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1258\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1259\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1260\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1300\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1307\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1247\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1326\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1360\n",
      "Epoch: 4/100... Training loss: 0.1288\n",
      "Epoch: 4/100... Training loss: 0.1381\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1277\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1258\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1298\n",
      "Epoch: 4/100... Training loss: 0.1301\n",
      "Epoch: 4/100... Training loss: 0.1291\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1285\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1284\n",
      "Epoch: 4/100... Training loss: 0.1264\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1289\n",
      "Epoch: 4/100... Training loss: 0.1296\n",
      "Epoch: 4/100... Training loss: 0.1263\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1274\n",
      "Epoch: 4/100... Training loss: 0.1320\n",
      "Epoch: 4/100... Training loss: 0.1322\n",
      "Epoch: 4/100... Training loss: 0.1299\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1306\n",
      "Epoch: 4/100... Training loss: 0.1309\n",
      "Epoch: 4/100... Training loss: 0.1287\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1336\n",
      "Epoch: 4/100... Training loss: 0.1255\n",
      "Epoch: 4/100... Training loss: 0.1303\n",
      "Epoch: 4/100... Training loss: 0.1329\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1295\n",
      "Epoch: 4/100... Training loss: 0.1281\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1316\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1223\n",
      "Epoch: 4/100... Training loss: 0.1283\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1293\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1254\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1311\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1261\n",
      "Epoch: 4/100... Training loss: 0.1290\n",
      "Epoch: 4/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1265\n",
      "Epoch: 4/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1285\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1305\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1327\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1285\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1326\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1301\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1321\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1321\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1232\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1230\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1282\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1256\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1262\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1326\n",
      "Epoch: 5/100... Training loss: 0.1206\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1231\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1243\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1254\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 5/100... Training loss: 0.1212\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1218\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1188\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1178\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1264\n",
      "Epoch: 5/100... Training loss: 0.1273\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1194\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1228\n",
      "Epoch: 5/100... Training loss: 0.1286\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1265\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1219\n",
      "Epoch: 5/100... Training loss: 0.1246\n",
      "Epoch: 5/100... Training loss: 0.1259\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1261\n",
      "Epoch: 5/100... Training loss: 0.1238\n",
      "Epoch: 5/100... Training loss: 0.1214\n",
      "Epoch: 5/100... Training loss: 0.1236\n",
      "Epoch: 5/100... Training loss: 0.1213\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1237\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1208\n",
      "Epoch: 5/100... Training loss: 0.1215\n",
      "Epoch: 5/100... Training loss: 0.1203\n",
      "Epoch: 5/100... Training loss: 0.1216\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1209\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1198\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1235\n",
      "Epoch: 5/100... Training loss: 0.1252\n",
      "Epoch: 5/100... Training loss: 0.1224\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1257\n",
      "Epoch: 5/100... Training loss: 0.1242\n",
      "Epoch: 5/100... Training loss: 0.1266\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1244\n",
      "Epoch: 5/100... Training loss: 0.1245\n",
      "Epoch: 5/100... Training loss: 0.1239\n",
      "Epoch: 5/100... Training loss: 0.1204\n",
      "Epoch: 5/100... Training loss: 0.1240\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1233\n",
      "Epoch: 5/100... Training loss: 0.1253\n",
      "Epoch: 5/100... Training loss: 0.1250\n",
      "Epoch: 5/100... Training loss: 0.1249\n",
      "Epoch: 5/100... Training loss: 0.1229\n",
      "Epoch: 5/100... Training loss: 0.1271\n",
      "Epoch: 5/100... Training loss: 0.1251\n",
      "Epoch: 5/100... Training loss: 0.1269\n",
      "Epoch: 5/100... Training loss: 0.1258\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1227\n",
      "Epoch: 5/100... Training loss: 0.1225\n",
      "Epoch: 5/100... Training loss: 0.1255\n",
      "Epoch: 5/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1284\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1296\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1164\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1272\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1290\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1304\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1229\n",
      "Epoch: 6/100... Training loss: 0.1179\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1183\n",
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1177\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1180\n",
      "Epoch: 6/100... Training loss: 0.1250\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1209\n",
      "Epoch: 6/100... Training loss: 0.1237\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1193\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1223\n",
      "Epoch: 6/100... Training loss: 0.1215\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1240\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1243\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1163\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1185\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1216\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1194\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1200\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1239\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1190\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1182\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1179\n",
      "Epoch: 6/100... Training loss: 0.1202\n",
      "Epoch: 6/100... Training loss: 0.1203\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1225\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 6/100... Training loss: 0.1213\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1181\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1226\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100... Training loss: 0.1220\n",
      "Epoch: 6/100... Training loss: 0.1224\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1174\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1218\n",
      "Epoch: 6/100... Training loss: 0.1180\n",
      "Epoch: 6/100... Training loss: 0.1208\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1198\n",
      "Epoch: 6/100... Training loss: 0.1171\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1211\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1145\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1238\n",
      "Epoch: 6/100... Training loss: 0.1191\n",
      "Epoch: 6/100... Training loss: 0.1205\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1204\n",
      "Epoch: 6/100... Training loss: 0.1189\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1180\n",
      "Epoch: 6/100... Training loss: 0.1231\n",
      "Epoch: 6/100... Training loss: 0.1164\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1206\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1186\n",
      "Epoch: 6/100... Training loss: 0.1196\n",
      "Epoch: 6/100... Training loss: 0.1219\n",
      "Epoch: 6/100... Training loss: 0.1201\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1230\n",
      "Epoch: 6/100... Training loss: 0.1207\n",
      "Epoch: 6/100... Training loss: 0.1169\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1199\n",
      "Epoch: 6/100... Training loss: 0.1192\n",
      "Epoch: 6/100... Training loss: 0.1195\n",
      "Epoch: 6/100... Training loss: 0.1175\n",
      "Epoch: 6/100... Training loss: 0.1188\n",
      "Epoch: 6/100... Training loss: 0.1214\n",
      "Epoch: 6/100... Training loss: 0.1221\n",
      "Epoch: 6/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1158\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1265\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1246\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1154\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1178\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1161\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1229\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1156\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1163\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1147\n",
      "Epoch: 7/100... Training loss: 0.1161\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1215\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1145\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1177\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1195\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1141\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1153\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1184\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1153\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1151\n",
      "Epoch: 7/100... Training loss: 0.1183\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1146\n",
      "Epoch: 7/100... Training loss: 0.1203\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1194\n",
      "Epoch: 7/100... Training loss: 0.1190\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1205\n",
      "Epoch: 7/100... Training loss: 0.1144\n",
      "Epoch: 7/100... Training loss: 0.1150\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1166\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1168\n",
      "Epoch: 7/100... Training loss: 0.1199\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1185\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1228\n",
      "Epoch: 7/100... Training loss: 0.1167\n",
      "Epoch: 7/100... Training loss: 0.1174\n",
      "Epoch: 7/100... Training loss: 0.1188\n",
      "Epoch: 7/100... Training loss: 0.1160\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1178\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1187\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1135\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1213\n",
      "Epoch: 7/100... Training loss: 0.1221\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1138\n",
      "Epoch: 7/100... Training loss: 0.1210\n",
      "Epoch: 7/100... Training loss: 0.1189\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1134\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1143\n",
      "Epoch: 7/100... Training loss: 0.1186\n",
      "Epoch: 7/100... Training loss: 0.1251\n",
      "Epoch: 7/100... Training loss: 0.1197\n",
      "Epoch: 7/100... Training loss: 0.1114\n",
      "Epoch: 7/100... Training loss: 0.1161\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1148\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1191\n",
      "Epoch: 7/100... Training loss: 0.1172\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1179\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1192\n",
      "Epoch: 7/100... Training loss: 0.1173\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1171\n",
      "Epoch: 7/100... Training loss: 0.1152\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1169\n",
      "Epoch: 7/100... Training loss: 0.1180\n",
      "Epoch: 7/100... Training loss: 0.1176\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1120\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1143\n",
      "Epoch: 7/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1247\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1249\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1124\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1243\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1129\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1159\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1109\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1142\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1147\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1122\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1259\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1182\n",
      "Epoch: 8/100... Training loss: 0.1113\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1133\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1117\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1142\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1150\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1132\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1126\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1132\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1134\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1167\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1145\n",
      "Epoch: 8/100... Training loss: 0.1125\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1158\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1164\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1181\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1183\n",
      "Epoch: 8/100... Training loss: 0.1118\n",
      "Epoch: 8/100... Training loss: 0.1127\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1177\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1176\n",
      "Epoch: 8/100... Training loss: 0.1143\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1173\n",
      "Epoch: 8/100... Training loss: 0.1166\n",
      "Epoch: 8/100... Training loss: 0.1156\n",
      "Epoch: 8/100... Training loss: 0.1152\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1163\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1148\n",
      "Epoch: 8/100... Training loss: 0.1162\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1139\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1179\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1169\n",
      "Epoch: 8/100... Training loss: 0.1186\n",
      "Epoch: 8/100... Training loss: 0.1146\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1120\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1140\n",
      "Epoch: 8/100... Training loss: 0.1153\n",
      "Epoch: 8/100... Training loss: 0.1136\n",
      "Epoch: 8/100... Training loss: 0.1161\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1151\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1160\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1131\n",
      "Epoch: 8/100... Training loss: 0.1154\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1125\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1175\n",
      "Epoch: 8/100... Training loss: 0.1172\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1138\n",
      "Epoch: 8/100... Training loss: 0.1174\n",
      "Epoch: 8/100... Training loss: 0.1149\n",
      "Epoch: 8/100... Training loss: 0.1155\n",
      "Epoch: 8/100... Training loss: 0.1168\n",
      "Epoch: 8/100... Training loss: 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1125\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1120\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1139\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1147\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1099\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1156\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1145\n",
      "Epoch: 9/100... Training loss: 0.1140\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1102\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1104\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1133\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1105\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1112\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1131\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1119\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1123\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1134\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1176\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1154\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1110\n",
      "Epoch: 9/100... Training loss: 0.1137\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1159\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1117\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1115\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1157\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1141\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1119\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1134\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1144\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1155\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1142\n",
      "Epoch: 9/100... Training loss: 0.1128\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1108\n",
      "Epoch: 9/100... Training loss: 0.1122\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1148\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1138\n",
      "Epoch: 9/100... Training loss: 0.1143\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1129\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1149\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1132\n",
      "Epoch: 9/100... Training loss: 0.1146\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1121\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1136\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1152\n",
      "Epoch: 9/100... Training loss: 0.1150\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1160\n",
      "Epoch: 9/100... Training loss: 0.1153\n",
      "Epoch: 9/100... Training loss: 0.1162\n",
      "Epoch: 9/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1105\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1102\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1209\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1130\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1091\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1113\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1113\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1104\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1103\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1116\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1115\n",
      "Epoch: 10/100... Training loss: 0.1121\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1132\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1106\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1137\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1105\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1110\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1101\n",
      "Epoch: 10/100... Training loss: 0.1212\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1111\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1144\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1125\n",
      "Epoch: 10/100... Training loss: 0.1122\n",
      "Epoch: 10/100... Training loss: 0.1088\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1096\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1184\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1163\n",
      "Epoch: 10/100... Training loss: 0.1113\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1150\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1136\n",
      "Epoch: 10/100... Training loss: 0.1089\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1090\n",
      "Epoch: 10/100... Training loss: 0.1129\n",
      "Epoch: 10/100... Training loss: 0.1123\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1118\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1134\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1098\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1078\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1109\n",
      "Epoch: 10/100... Training loss: 0.1133\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1124\n",
      "Epoch: 10/100... Training loss: 0.1143\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1140\n",
      "Epoch: 10/100... Training loss: 0.1105\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1099\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1128\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1101\n",
      "Epoch: 10/100... Training loss: 0.1112\n",
      "Epoch: 10/100... Training loss: 0.1113\n",
      "Epoch: 10/100... Training loss: 0.1120\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1119\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1184\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1183\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1093\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1091\n",
      "Epoch: 11/100... Training loss: 0.1093\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1074\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1107\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1095\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1097\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1079\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1091\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1088\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1094\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1090\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1060\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1091\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1117\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1140\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1097\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1125\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1111\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1100\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1105\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1106\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1195\n",
      "Epoch: 11/100... Training loss: 0.1113\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1088\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1092\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1134\n",
      "Epoch: 11/100... Training loss: 0.1101\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1114\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1098\n",
      "Epoch: 11/100... Training loss: 0.1096\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1097\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1104\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1121\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1086\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1069\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1072\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1118\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100... Training loss: 0.1152\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1119\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1115\n",
      "Epoch: 11/100... Training loss: 0.1103\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1120\n",
      "Epoch: 11/100... Training loss: 0.1127\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1132\n",
      "Epoch: 11/100... Training loss: 0.1131\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1116\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1099\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1109\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1129\n",
      "Epoch: 11/100... Training loss: 0.1122\n",
      "Epoch: 11/100... Training loss: 0.1102\n",
      "Epoch: 11/100... Training loss: 0.1128\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1110\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1133\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1178\n",
      "Epoch: 12/100... Training loss: 0.1161\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1066\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1167\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1085\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1148\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1098\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1177\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1102\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1096\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1186\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1100\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1105\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1153\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1092\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1148\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1090\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1070\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1106\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1108\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1087\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1103\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1109\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1095\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1112\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1115\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1091\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1089\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1136\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1101\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1088\n",
      "Epoch: 12/100... Training loss: 0.1069\n",
      "Epoch: 12/100... Training loss: 0.1097\n",
      "Epoch: 12/100... Training loss: 0.1113\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1075\n",
      "Epoch: 12/100... Training loss: 0.1107\n",
      "Epoch: 12/100... Training loss: 0.1080\n",
      "Epoch: 12/100... Training loss: 0.1119\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1132\n",
      "Epoch: 12/100... Training loss: 0.1110\n",
      "Epoch: 12/100... Training loss: 0.1128\n",
      "Epoch: 12/100... Training loss: 0.1094\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1084\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1111\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1155\n",
      "Epoch: 13/100... Training loss: 0.1177\n",
      "Epoch: 13/100... Training loss: 0.1146\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1167\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1167\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1166\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1175\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1134\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1162\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1067\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1067\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1079\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1070\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1071\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1073\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1077\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1106\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1091\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1081\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1090\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1109\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1097\n",
      "Epoch: 13/100... Training loss: 0.1080\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1078\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1102\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1084\n",
      "Epoch: 13/100... Training loss: 0.1083\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1099\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1085\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1114\n",
      "Epoch: 13/100... Training loss: 0.1103\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1070\n",
      "Epoch: 13/100... Training loss: 0.1088\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1101\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1122\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1086\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1104\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1087\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1094\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1075\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1064\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1120\n",
      "Epoch: 13/100... Training loss: 0.1112\n",
      "Epoch: 13/100... Training loss: 0.1093\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1156\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1153\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1077\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1063\n",
      "Epoch: 14/100... Training loss: 0.1072\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1144\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1151\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1121\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1151\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1070\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1163\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1152\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1119\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1162\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1079\n",
      "Epoch: 14/100... Training loss: 0.1057\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1054\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1084\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1111\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 14/100... Training loss: 0.1127\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1114\n",
      "Epoch: 14/100... Training loss: 0.1117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1086\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1089\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1097\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1083\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1111\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1158\n",
      "Epoch: 14/100... Training loss: 0.1074\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1075\n",
      "Epoch: 14/100... Training loss: 0.1082\n",
      "Epoch: 14/100... Training loss: 0.1081\n",
      "Epoch: 14/100... Training loss: 0.1139\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1103\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1092\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1071\n",
      "Epoch: 14/100... Training loss: 0.1101\n",
      "Epoch: 14/100... Training loss: 0.1144\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1080\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1061\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1091\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1076\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1087\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1068\n",
      "Epoch: 14/100... Training loss: 0.1111\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1090\n",
      "Epoch: 14/100... Training loss: 0.1105\n",
      "Epoch: 14/100... Training loss: 0.1078\n",
      "Epoch: 14/100... Training loss: 0.1095\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1088\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1156\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1129\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1033\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1057\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1168\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1146\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1071\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1056\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1081\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1152\n",
      "Epoch: 15/100... Training loss: 0.1091\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1057\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1058\n",
      "Epoch: 15/100... Training loss: 0.1072\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100... Training loss: 0.1149\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1063\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1136\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1074\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1141\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1061\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1114\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1082\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1104\n",
      "Epoch: 15/100... Training loss: 0.1084\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1067\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1069\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1044\n",
      "Epoch: 15/100... Training loss: 0.1073\n",
      "Epoch: 15/100... Training loss: 0.1052\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1049\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1070\n",
      "Epoch: 15/100... Training loss: 0.1086\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1136\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1129\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1095\n",
      "Epoch: 15/100... Training loss: 0.1080\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1052\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1088\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1089\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1153\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1129\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1076\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1078\n",
      "Epoch: 15/100... Training loss: 0.1068\n",
      "Epoch: 15/100... Training loss: 0.1159\n",
      "Epoch: 15/100... Training loss: 0.1083\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1077\n",
      "Epoch: 15/100... Training loss: 0.1094\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1075\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1051\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1043\n",
      "Epoch: 16/100... Training loss: 0.1056\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1136\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1155\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1082\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1065\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1058\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1069\n",
      "Epoch: 16/100... Training loss: 0.1143\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1075\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1063\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1061\n",
      "Epoch: 16/100... Training loss: 0.1062\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1051\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1150\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1086\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1064\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1037\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1071\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1068\n",
      "Epoch: 16/100... Training loss: 0.1087\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1050\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1073\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1070\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1072\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1025\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1066\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1074\n",
      "Epoch: 16/100... Training loss: 0.1051\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1077\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1090\n",
      "Epoch: 16/100... Training loss: 0.1101\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1067\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1092\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1085\n",
      "Epoch: 16/100... Training loss: 0.1059\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1088\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1128\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1144\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1035\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1057\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1038\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1045\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1123\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1146\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1022\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1048\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1134\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1146\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1061\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1041\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1053\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1050\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1119\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1038\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1078\n",
      "Epoch: 17/100... Training loss: 0.1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1060\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1058\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1067\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1040\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1046\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1049\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1080\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1073\n",
      "Epoch: 17/100... Training loss: 0.1054\n",
      "Epoch: 17/100... Training loss: 0.1064\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1091\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1123\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1070\n",
      "Epoch: 17/100... Training loss: 0.1063\n",
      "Epoch: 17/100... Training loss: 0.1069\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1090\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1077\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1128\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1074\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1035\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1071\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1075\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1062\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1055\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1042\n",
      "Epoch: 17/100... Training loss: 0.1065\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1044\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1052\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1134\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1048\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1038\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1129\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1041\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1053\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1022\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1057\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1056\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1075\n",
      "Epoch: 18/100... Training loss: 0.1066\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1054\n",
      "Epoch: 18/100... Training loss: 0.1061\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1072\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1051\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1028\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1064\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1045\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1043\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1030\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1057\n",
      "Epoch: 18/100... Training loss: 0.1069\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1058\n",
      "Epoch: 18/100... Training loss: 0.1068\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1018\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1067\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1063\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1047\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1074\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1060\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1062\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1082\n",
      "Epoch: 18/100... Training loss: 0.1059\n",
      "Epoch: 18/100... Training loss: 0.1073\n",
      "Epoch: 18/100... Training loss: 0.1065\n",
      "Epoch: 18/100... Training loss: 0.1043\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1021\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1127\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1126\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1124\n",
      "Epoch: 19/100... Training loss: 0.1057\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1024\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1165\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1038\n",
      "Epoch: 19/100... Training loss: 0.1106\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1035\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1122\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1026\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1040\n",
      "Epoch: 19/100... Training loss: 0.1039\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1065\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1025\n",
      "Epoch: 19/100... Training loss: 0.1093\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1044\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1033\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 19/100... Training loss: 0.1041\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1036\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1055\n",
      "Epoch: 19/100... Training loss: 0.1058\n",
      "Epoch: 19/100... Training loss: 0.1063\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1068\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1056\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1123\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1053\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1045\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1042\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1124\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1052\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1047\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1046\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1060\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1071\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1066\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1049\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1050\n",
      "Epoch: 19/100... Training loss: 0.1089\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1059\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1028\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1031\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1123\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1123\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1040\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1026\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1032\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1042\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1044\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1055\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1049\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1065\n",
      "Epoch: 20/100... Training loss: 0.1027\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1039\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1062\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1071\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1134\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1036\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1050\n",
      "Epoch: 20/100... Training loss: 0.1061\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1123\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1048\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1055\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1060\n",
      "Epoch: 20/100... Training loss: 0.1079\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1038\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1063\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1104\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1069\n",
      "Epoch: 20/100... Training loss: 0.1015\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1046\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1041\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1064\n",
      "Epoch: 20/100... Training loss: 0.1033\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1056\n",
      "Epoch: 20/100... Training loss: 0.1054\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1028\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1053\n",
      "Epoch: 20/100... Training loss: 0.1052\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1038\n",
      "Epoch: 20/100... Training loss: 0.1051\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1024\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1105\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1104\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1032\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1019\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1124\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1104\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1030\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1111\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1028\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1099\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1074\n",
      "Epoch: 21/100... Training loss: 0.1025\n",
      "Epoch: 21/100... Training loss: 0.1138\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1108\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1036\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1055\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1045\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1025\n",
      "Epoch: 21/100... Training loss: 0.1014\n",
      "Epoch: 21/100... Training loss: 0.1021\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1099\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1052\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1027\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1039\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1056\n",
      "Epoch: 21/100... Training loss: 0.1105\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1037\n",
      "Epoch: 21/100... Training loss: 0.1033\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1041\n",
      "Epoch: 21/100... Training loss: 0.1051\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1012\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1049\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1059\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1054\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1048\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1043\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1090\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1030\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.0995\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1112\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1014\n",
      "Epoch: 22/100... Training loss: 0.1116\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1017\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1037\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1103\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1023\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1022\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1027\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1034\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1021\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1038\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1033\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1022\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1014\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1031\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1044\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1062\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1024\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1045\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1023\n",
      "Epoch: 22/100... Training loss: 0.1073\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1049\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1047\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1057\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1055\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1014\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1046\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1061\n",
      "Epoch: 22/100... Training loss: 0.1023\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1042\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1054\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1036\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1109\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1082\n",
      "Epoch: 22/100... Training loss: 0.1068\n",
      "Epoch: 22/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1014\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1032\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1106\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1022\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1108\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1023\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1030\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1097\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1033\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.0998\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1049\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1019\n",
      "Epoch: 23/100... Training loss: 0.1115\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1085\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1105\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1120\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1105\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1036\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1017\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1031\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1037\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1014\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1022\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1024\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1051\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1025\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1018\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1101\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1038\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1035\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1057\n",
      "Epoch: 23/100... Training loss: 0.1039\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1047\n",
      "Epoch: 23/100... Training loss: 0.1046\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1042\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1027\n",
      "Epoch: 23/100... Training loss: 0.1048\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1040\n",
      "Epoch: 23/100... Training loss: 0.1071\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1026\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1045\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1030\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1112\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1030\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1032\n",
      "Epoch: 24/100... Training loss: 0.1025\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1017\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1018\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1041\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1025\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1025\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1044\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1026\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1043\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1018\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1092\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1119\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1033\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1038\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1022\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1013\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1058\n",
      "Epoch: 24/100... Training loss: 0.1022\n",
      "Epoch: 24/100... Training loss: 0.1035\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1100\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1034\n",
      "Epoch: 24/100... Training loss: 0.1105\n",
      "Epoch: 24/100... Training loss: 0.1016\n",
      "Epoch: 24/100... Training loss: 0.1028\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1016\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1023\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1025\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1040\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1037\n",
      "Epoch: 24/100... Training loss: 0.1030\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1065\n",
      "Epoch: 24/100... Training loss: 0.1042\n",
      "Epoch: 24/100... Training loss: 0.1071\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1029\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1020\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1012\n",
      "Epoch: 24/100... Training loss: 0.1062\n",
      "Epoch: 24/100... Training loss: 0.1050\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1027\n",
      "Epoch: 24/100... Training loss: 0.1036\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1046\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1109\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1024\n",
      "Epoch: 25/100... Training loss: 0.0999\n",
      "Epoch: 25/100... Training loss: 0.1108\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1010\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1015\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1010\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1012\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1026\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1016\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1114\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1026\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1117\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1019\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1097\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1002\n",
      "Epoch: 25/100... Training loss: 0.1017\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1034\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1042\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1020\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1018\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1040\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1036\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1035\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1030\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1032\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1051\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1048\n",
      "Epoch: 25/100... Training loss: 0.1031\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1013\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1027\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1102\n",
      "Epoch: 25/100... Training loss: 0.1045\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1065\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1033\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1044\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1020\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1020\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1011\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1082\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1026\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1014\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1013\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1004\n",
      "Epoch: 26/100... Training loss: 0.1008\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1082\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1007\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1020\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1007\n",
      "Epoch: 26/100... Training loss: 0.1035\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1016\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1027\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1021\n",
      "Epoch: 26/100... Training loss: 0.1029\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1082\n",
      "Epoch: 26/100... Training loss: 0.1024\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100... Training loss: 0.1044\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1025\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1030\n",
      "Epoch: 26/100... Training loss: 0.1040\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1022\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1018\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1028\n",
      "Epoch: 26/100... Training loss: 0.1038\n",
      "Epoch: 26/100... Training loss: 0.1031\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1023\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1034\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1033\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1015\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1082\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1105\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1115\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.0990\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1094\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.0973\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1004\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1018\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1022\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1024\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1094\n",
      "Epoch: 27/100... Training loss: 0.1026\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1014\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1011\n",
      "Epoch: 27/100... Training loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1019\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1020\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1012\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1011\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1035\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1007\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1031\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1033\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1038\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1017\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1029\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1016\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 27/100... Training loss: 0.1044\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1023\n",
      "Epoch: 27/100... Training loss: 0.1027\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1028\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1021\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1040\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1100\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1024\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1011\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1010\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100... Training loss: 0.1003\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1015\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1014\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1005\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1012\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1000\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1017\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.0998\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1025\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1020\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.0997\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1038\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1021\n",
      "Epoch: 28/100... Training loss: 0.1028\n",
      "Epoch: 28/100... Training loss: 0.0998\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1032\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1016\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1019\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1007\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1037\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1009\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1030\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1023\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1012\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1022\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100... Training loss: 0.1039\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1040\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1031\n",
      "Epoch: 28/100... Training loss: 0.1059\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1002\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1020\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1009\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.0993\n",
      "Epoch: 29/100... Training loss: 0.1090\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1092\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1008\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1097\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1020\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1006\n",
      "Epoch: 29/100... Training loss: 0.1003\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.0997\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.0996\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1011\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1068\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1036\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1001\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1097\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1019\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.0985\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1018\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1022\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1002\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1029\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1093\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1012\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1010\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1003\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1035\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1099\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1016\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1031\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.0995\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1027\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1020\n",
      "Epoch: 29/100... Training loss: 0.1038\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.0998\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1007\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1030\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1003\n",
      "Epoch: 29/100... Training loss: 0.1014\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1023\n",
      "Epoch: 29/100... Training loss: 0.1034\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1079\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1028\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1002\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1079\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1088\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1015\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1079\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1003\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1097\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1010\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1006\n",
      "Epoch: 30/100... Training loss: 0.0997\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1021\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1006\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1025\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1076\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1011\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1078\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1024\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1020\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.0991\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1008\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1009\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1031\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1023\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1010\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1022\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1019\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1043\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1010\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1030\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1037\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1041\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1075\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1091\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.0990\n",
      "Epoch: 31/100... Training loss: 0.1007\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.0996\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1004\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1086\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1006\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1005\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.0987\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1004\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1104\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.0993\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1017\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1008\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1018\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1013\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1091\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1009\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.0997\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1023\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1044\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1065\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1001\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1014\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1039\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1022\n",
      "Epoch: 31/100... Training loss: 0.1035\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1010\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1037\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.0982\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1011\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1019\n",
      "Epoch: 31/100... Training loss: 0.1016\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1026\n",
      "Epoch: 31/100... Training loss: 0.1045\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1034\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1024\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.0989\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1066\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1001\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1002\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1007\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1092\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1013\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1012\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.0992\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1010\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1066\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1087\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.1026\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.0981\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1009\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1030\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1008\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1011\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1018\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1000\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1023\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1005\n",
      "Epoch: 32/100... Training loss: 0.0991\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.0987\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1002\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1022\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1014\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1041\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1025\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1019\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.0989\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1072\n",
      "Epoch: 33/100... Training loss: 0.1010\n",
      "Epoch: 33/100... Training loss: 0.1004\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1000\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1084\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1091\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.0980\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1099\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1022\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1009\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1030\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1084\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1072\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.0992\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1007\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.0996\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.0997\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1002\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1004\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1023\n",
      "Epoch: 33/100... Training loss: 0.1028\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1026\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1018\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1001\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1017\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1006\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.0983\n",
      "Epoch: 33/100... Training loss: 0.1068\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1027\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1013\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1032\n",
      "Epoch: 33/100... Training loss: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1005\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1066\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1012\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1016\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1071\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.0991\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1069\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.0997\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.0989\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1091\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1069\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1006\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1082\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.0988\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1007\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1089\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.0990\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1006\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1013\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1009\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1015\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1014\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1004\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1034\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.0998\n",
      "Epoch: 34/100... Training loss: 0.1012\n",
      "Epoch: 34/100... Training loss: 0.1005\n",
      "Epoch: 34/100... Training loss: 0.1008\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1022\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.0989\n",
      "Epoch: 34/100... Training loss: 0.1069\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1028\n",
      "Epoch: 34/100... Training loss: 0.1011\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1001\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.0981\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1074\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.0990\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.0975\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.0982\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.0992\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1070\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.0978\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1070\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1086\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1004\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.0983\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.0986\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1015\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.0992\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1015\n",
      "Epoch: 35/100... Training loss: 0.1087\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.0998\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1003\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1019\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1020\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1006\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1013\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1012\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1016\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1022\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.0995\n",
      "Epoch: 35/100... Training loss: 0.1014\n",
      "Epoch: 35/100... Training loss: 0.1029\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1044\n",
      "Epoch: 35/100... Training loss: 0.1005\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1018\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1011\n",
      "Epoch: 35/100... Training loss: 0.1026\n",
      "Epoch: 35/100... Training loss: 0.1009\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.0999\n",
      "Epoch: 35/100... Training loss: 0.1002\n",
      "Epoch: 35/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.0980\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.0990\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1065\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1096\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1012\n",
      "Epoch: 36/100... Training loss: 0.1065\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1065\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.0985\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.0962\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.0999\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1009\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.0987\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1006\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.0989\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.0991\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1077\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1067\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1071\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1010\n",
      "Epoch: 36/100... Training loss: 0.1035\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1007\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1028\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1005\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1001\n",
      "Epoch: 36/100... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1083\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1076\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1071\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1017\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1016\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1003\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1002\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1011\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1015\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1006\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1004\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.0997\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.0995\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1025\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.0965\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1064\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.0996\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1074\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.0995\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1005\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1081\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1084\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.0992\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.0989\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.0970\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.0987\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.1014\n",
      "Epoch: 37/100... Training loss: 0.1094\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.0990\n",
      "Epoch: 37/100... Training loss: 0.1001\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.0998\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1084\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1003\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1010\n",
      "Epoch: 37/100... Training loss: 0.0992\n",
      "Epoch: 37/100... Training loss: 0.1000\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.0994\n",
      "Epoch: 37/100... Training loss: 0.1012\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1033\n",
      "Epoch: 37/100... Training loss: 0.1008\n",
      "Epoch: 37/100... Training loss: 0.0999\n",
      "Epoch: 37/100... Training loss: 0.1009\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1019\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1016\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1059\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.0980\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.0986\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.0992\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1069\n",
      "Epoch: 38/100... Training loss: 0.0998\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1059\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1073\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1001\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1073\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.0974\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.0993\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.0996\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.0997\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.0997\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1059\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1015\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.0976\n",
      "Epoch: 38/100... Training loss: 0.1010\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1076\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.0987\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.0995\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1008\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.0999\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1077\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.0983\n",
      "Epoch: 38/100... Training loss: 0.1017\n",
      "Epoch: 38/100... Training loss: 0.1031\n",
      "Epoch: 38/100... Training loss: 0.1004\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1019\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1007\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1003\n",
      "Epoch: 38/100... Training loss: 0.0982\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1006\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1026\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.0991\n",
      "Epoch: 38/100... Training loss: 0.1013\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1002\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1011\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1023\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.0991\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.0996\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.0990\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1003\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.0991\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.0981\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1073\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1022\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.0994\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1003\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1002\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1077\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1016\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.0986\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1070\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1013\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1080\n",
      "Epoch: 39/100... Training loss: 0.1004\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.0992\n",
      "Epoch: 39/100... Training loss: 0.0961\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1008\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1017\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.0987\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1006\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1000\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1009\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 39/100... Training loss: 0.0984\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1015\n",
      "Epoch: 39/100... Training loss: 0.0988\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.0995\n",
      "Epoch: 39/100... Training loss: 0.1064\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.0999\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1012\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1079\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1055\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1000\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.0981\n",
      "Epoch: 40/100... Training loss: 0.0982\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.0952\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.0980\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1016\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.0984\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1072\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.0998\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.0988\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.0999\n",
      "Epoch: 40/100... Training loss: 0.0989\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.0996\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1055\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.1018\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.0995\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1001\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.0979\n",
      "Epoch: 40/100... Training loss: 0.0985\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.0981\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0984\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1012\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1011\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1068\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1023\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.0995\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.0997\n",
      "Epoch: 40/100... Training loss: 0.1007\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1002\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.0986\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.0993\n",
      "Epoch: 40/100... Training loss: 0.1005\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.0997\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.0987\n",
      "Epoch: 41/100... Training loss: 0.1044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1008\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1000\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.0982\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.0976\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1001\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1064\n",
      "Epoch: 41/100... Training loss: 0.1065\n",
      "Epoch: 41/100... Training loss: 0.0988\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1094\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.0986\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1004\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.0999\n",
      "Epoch: 41/100... Training loss: 0.1066\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.0988\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.0985\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.0976\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.0995\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.0996\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1083\n",
      "Epoch: 41/100... Training loss: 0.0988\n",
      "Epoch: 41/100... Training loss: 0.0994\n",
      "Epoch: 41/100... Training loss: 0.1010\n",
      "Epoch: 41/100... Training loss: 0.1058\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1015\n",
      "Epoch: 41/100... Training loss: 0.1002\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1005\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.0981\n",
      "Epoch: 41/100... Training loss: 0.0964\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.0989\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1014\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.0986\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1076\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.0998\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.0993\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1006\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1054\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.0992\n",
      "Epoch: 42/100... Training loss: 0.0970\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.0973\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.0986\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.0982\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.0984\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.0996\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.1054\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.0978\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.0982\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1063\n",
      "Epoch: 42/100... Training loss: 0.1015\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1065\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.0993\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1058\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1007\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1006\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.0991\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1001\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1059\n",
      "Epoch: 42/100... Training loss: 0.0987\n",
      "Epoch: 42/100... Training loss: 0.0998\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.0999\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.0968\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.0997\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1003\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.0994\n",
      "Epoch: 42/100... Training loss: 0.1084\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.0989\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.0985\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1065\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1008\n",
      "Epoch: 42/100... Training loss: 0.1058\n",
      "Epoch: 42/100... Training loss: 0.0972\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.0995\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1011\n",
      "Epoch: 42/100... Training loss: 0.1019\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.0992\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1069\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1068\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.0976\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.0980\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.0987\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.0985\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.0953\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.0980\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.0981\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1000\n",
      "Epoch: 43/100... Training loss: 0.0988\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.0992\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1008\n",
      "Epoch: 43/100... Training loss: 0.0993\n",
      "Epoch: 43/100... Training loss: 0.0985\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1004\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1005\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1001\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.0996\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1012\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.0978\n",
      "Epoch: 43/100... Training loss: 0.0991\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1090\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.0994\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1009\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.0998\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.0986\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.0995\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1016\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.0984\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.0981\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.0974\n",
      "Epoch: 44/100... Training loss: 0.1074\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.0973\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.0987\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.0999\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.0980\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.0993\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.0981\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1069\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.0997\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1022\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.0984\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1072\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.0986\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.0990\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1006\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.0988\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.0998\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.0996\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1003\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.0995\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.0994\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.0992\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1010\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.0977\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.0967\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.0979\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1063\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.0977\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.0999\n",
      "Epoch: 45/100... Training loss: 0.1027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.0998\n",
      "Epoch: 45/100... Training loss: 0.0986\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.0983\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.0982\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.0994\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.0991\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.0963\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.0974\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.0997\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.0974\n",
      "Epoch: 45/100... Training loss: 0.1006\n",
      "Epoch: 45/100... Training loss: 0.0996\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1067\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.0959\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.0980\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.0987\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.0990\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.0980\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1074\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1027\n",
      "Epoch: 45/100... Training loss: 0.0995\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.0978\n",
      "Epoch: 45/100... Training loss: 0.0985\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1005\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1066\n",
      "Epoch: 46/100... Training loss: 0.0989\n",
      "Epoch: 46/100... Training loss: 0.0955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.0984\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.0970\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1060\n",
      "Epoch: 46/100... Training loss: 0.1075\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1062\n",
      "Epoch: 46/100... Training loss: 0.0984\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1052\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1070\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1055\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0989\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.0985\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.0980\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1059\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1052\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1052\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1055\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.0973\n",
      "Epoch: 46/100... Training loss: 0.0983\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.0988\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.0994\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1055\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.0990\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1067\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.0987\n",
      "Epoch: 46/100... Training loss: 0.0992\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.0938\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0981\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.0986\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1003\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.0997\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.0995\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.0981\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1060\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1009\n",
      "Epoch: 46/100... Training loss: 0.0981\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.0968\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1011\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1052\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1002\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.0998\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.0984\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.0988\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.0987\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1070\n",
      "Epoch: 47/100... Training loss: 0.1049\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1060\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.0978\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.0994\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.0992\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1005\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1059\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1065\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.0995\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.0970\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1059\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.0979\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.0983\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.0996\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1078\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.0997\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.0987\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.0960\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.0982\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1009\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.0990\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1004\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.0977\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1001\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1003\n",
      "Epoch: 47/100... Training loss: 0.0986\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1069\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1008\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.0979\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.0965\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1063\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1074\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.0983\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1000\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1069\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1050\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1072\n",
      "Epoch: 48/100... Training loss: 0.0999\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1061\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.0977\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.0981\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.0973\n",
      "Epoch: 48/100... Training loss: 0.0987\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.0994\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.0988\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1003\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.0991\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.0995\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1005\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0980\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.0984\n",
      "Epoch: 48/100... Training loss: 0.1007\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1077\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.0979\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0982\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.0991\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0976\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0988\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1061\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.0983\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1070\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1062\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1057\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.0980\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.0984\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.0986\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.0983\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.0989\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1001\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.0973\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0976\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.0985\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.1069\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.0979\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1007\n",
      "Epoch: 49/100... Training loss: 0.0970\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1002\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.0972\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0973\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1012\n",
      "Epoch: 49/100... Training loss: 0.1054\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.0993\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.1017\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1022\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.0963\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.0965\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.0971\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.0974\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.0978\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0983\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.0990\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.0996\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.0977\n",
      "Epoch: 50/100... Training loss: 0.0974\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.0969\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1075\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.0987\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1053\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.0965\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.0981\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1066\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.0980\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.0995\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.0970\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.0989\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.0981\n",
      "Epoch: 50/100... Training loss: 0.0992\n",
      "Epoch: 50/100... Training loss: 0.0985\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1011\n",
      "Epoch: 50/100... Training loss: 0.1009\n",
      "Epoch: 50/100... Training loss: 0.0982\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.0998\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1062\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1082\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.0966\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1000\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.0997\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1018\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1001\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0988\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1075\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.0973\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.0974\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.0971\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.0992\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.0966\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.0982\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.0989\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1068\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1010\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.0986\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1065\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.0964\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0980\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1005\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.0991\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0996\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.0990\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.0993\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1007\n",
      "Epoch: 51/100... Training loss: 0.0987\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.0987\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1054\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1061\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0970\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.0989\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.0968\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.0976\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0990\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1052\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.0981\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.0996\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1072\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0964\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.0992\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.0980\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.0968\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.0966\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0984\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0974\n",
      "Epoch: 52/100... Training loss: 0.0980\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1058\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1001\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.0991\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0972\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.0994\n",
      "Epoch: 52/100... Training loss: 0.0979\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1058\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0965\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.0973\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.0991\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.0985\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0970\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1003\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.0977\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.0975\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.0975\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.0987\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.0963\n",
      "Epoch: 53/100... Training loss: 0.0981\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.0971\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1042\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1039\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.0963\n",
      "Epoch: 53/100... Training loss: 0.1058\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1063\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1056\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.0994\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1051\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.0978\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.0987\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.0990\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.0971\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1067\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1062\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1011\n",
      "Epoch: 53/100... Training loss: 0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1042\n",
      "Epoch: 53/100... Training loss: 0.0997\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.0986\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.0982\n",
      "Epoch: 53/100... Training loss: 0.0988\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1051\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.0989\n",
      "Epoch: 53/100... Training loss: 0.1000\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.0980\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.0984\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1072\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.0984\n",
      "Epoch: 54/100... Training loss: 0.1067\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.0994\n",
      "Epoch: 54/100... Training loss: 0.0961\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0979\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.0972\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.0988\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.0976\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1060\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.0976\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.0990\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.0973\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1061\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1060\n",
      "Epoch: 54/100... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.0986\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.0983\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1060\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0978\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.0985\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1005\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.0992\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1062\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.0995\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.0997\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1060\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.0982\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.0976\n",
      "Epoch: 54/100... Training loss: 0.0963\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.0976\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1065\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0980\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.0991\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1013\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.0987\n",
      "Epoch: 54/100... Training loss: 0.0975\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1046\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.0982\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.0972\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.0965\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.0967\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.0977\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.0974\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.0970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.0994\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.0981\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0989\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.0985\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0974\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1066\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.0980\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1007\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.0995\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1053\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1052\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.0952\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.0964\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.0986\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.0967\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1002\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.0978\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.0984\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1000\n",
      "Epoch: 55/100... Training loss: 0.0987\n",
      "Epoch: 55/100... Training loss: 0.1096\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.0983\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1049\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.0966\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.0960\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.0983\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1056\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.0980\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.0973\n",
      "Epoch: 56/100... Training loss: 0.0979\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.0967\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.0968\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1053\n",
      "Epoch: 56/100... Training loss: 0.1053\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1049\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0992\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.0986\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0978\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.0948\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.0985\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100... Training loss: 0.1015\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1065\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.0983\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1055\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0982\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1057\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.0995\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.0990\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.0989\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1059\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1002\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.0965\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.0987\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.0977\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.0970\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.0966\n",
      "Epoch: 56/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.0950\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.0971\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0981\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1053\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0966\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0978\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0971\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1053\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0988\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1065\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.0970\n",
      "Epoch: 57/100... Training loss: 0.0965\n",
      "Epoch: 57/100... Training loss: 0.0990\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.0979\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.0966\n",
      "Epoch: 57/100... Training loss: 0.0966\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1062\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1001\n",
      "Epoch: 57/100... Training loss: 0.0984\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1051\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.0963\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.0975\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.0983\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.0980\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.0960\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.0973\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.0969\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1000\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1063\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1047\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1010\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0996\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.0985\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.0994\n",
      "Epoch: 57/100... Training loss: 0.1046\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.0987\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1063\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1056\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0953\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0983\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0976\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.0984\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1004\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.0985\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.0975\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.0977\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.0980\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0982\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.0981\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.0991\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1056\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.0959\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.0974\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0987\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.0971\n",
      "Epoch: 58/100... Training loss: 0.0986\n",
      "Epoch: 58/100... Training loss: 0.1047\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.0971\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.0981\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0955\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.0974\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.0974\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.0978\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.0974\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.0977\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.0966\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.0995\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0998\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0970\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.0976\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0980\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.0987\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.0984\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1000\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.0997\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.0985\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0983\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0965\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.0972\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.0999\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.0969\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0960\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.0988\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.0989\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1057\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1064\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1052\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1051\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0953\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0955\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0976\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1052\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1057\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0973\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1049\n",
      "Epoch: 60/100... Training loss: 0.0998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.0960\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.0985\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.0979\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.0962\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.0973\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.0965\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.0972\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.0976\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.0989\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.0994\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1057\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1056\n",
      "Epoch: 60/100... Training loss: 0.0983\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1055\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1046\n",
      "Epoch: 60/100... Training loss: 0.0986\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.0984\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.0973\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.0991\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0995\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0981\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.0978\n",
      "Epoch: 60/100... Training loss: 0.0982\n",
      "Epoch: 60/100... Training loss: 0.0959\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.0975\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.0952\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.0964\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0960\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0978\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1048\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1058\n",
      "Epoch: 61/100... Training loss: 0.0984\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.0966\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1048\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.0994\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.0982\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1056\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0998\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1053\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.0999\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0987\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.0964\n",
      "Epoch: 61/100... Training loss: 0.0986\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1047\n",
      "Epoch: 61/100... Training loss: 0.0962\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.0972\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0988\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.0979\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.0975\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.0981\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.0980\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.0977\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.0980\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1056\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1053\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.0974\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0949\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0983\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0980\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.0949\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1055\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.1052\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1071\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1058\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0989\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.0971\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1042\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0972\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1067\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.0963\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.0978\n",
      "Epoch: 62/100... Training loss: 0.0968\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.0987\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.0960\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0955\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.0951\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.0961\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.0990\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.0973\n",
      "Epoch: 62/100... Training loss: 0.0988\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.0979\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1038\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1059\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0970\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.0940\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0974\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0968\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.0966\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1040\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.0967\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0971\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1040\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0995\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.0976\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0986\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.0993\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.0991\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0971\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.0973\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.0978\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.0994\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0988\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1049\n",
      "Epoch: 63/100... Training loss: 0.1058\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1035\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1043\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0969\n",
      "Epoch: 64/100... Training loss: 0.0975\n",
      "Epoch: 64/100... Training loss: 0.0988\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0969\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0965\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1053\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.0983\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.0960\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0975\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1043\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.0976\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0985\n",
      "Epoch: 64/100... Training loss: 0.1045\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1054\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1035\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0977\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.0972\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.0979\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.0974\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.0986\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1060\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1063\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1056\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0972\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.1037\n",
      "Epoch: 65/100... Training loss: 0.0986\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.0962\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0976\n",
      "Epoch: 65/100... Training loss: 0.0957\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1037\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.0966\n",
      "Epoch: 65/100... Training loss: 0.0973\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.0974\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.1049\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0973\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.1042\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1059\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.0972\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.0983\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.0975\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.0972\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0971\n",
      "Epoch: 65/100... Training loss: 0.0965\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.0985\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1054\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0973\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.0958\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0948\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1046\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1002\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0967\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.0966\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0991\n",
      "Epoch: 65/100... Training loss: 0.1052\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.0973\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0977\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.0972\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0995\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.0981\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.0958\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.0965\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0981\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.1050\n",
      "Epoch: 66/100... Training loss: 0.1040\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.0966\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0955\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.0948\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0972\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1058\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1040\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0971\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0970\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1061\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1042\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0964\n",
      "Epoch: 66/100... Training loss: 0.1046\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.0973\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0969\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1053\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0978\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1053\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.0991\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1036\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.0968\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.0976\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.0979\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.0977\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0955\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0996\n",
      "Epoch: 66/100... Training loss: 0.0975\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1036\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1036\n",
      "Epoch: 66/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0964\n",
      "Epoch: 67/100... Training loss: 0.1055\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1047\n",
      "Epoch: 67/100... Training loss: 0.0982\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0958\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0987\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.0945\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.0981\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0989\n",
      "Epoch: 67/100... Training loss: 0.0974\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.0954\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1054\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1052\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0977\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.0984\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0971\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.0966\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.0985\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1002\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1054\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.0986\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0948\n",
      "Epoch: 67/100... Training loss: 0.0995\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.0992\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1037\n",
      "Epoch: 67/100... Training loss: 0.0964\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0983\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0973\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.0976\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.0990\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.0966\n",
      "Epoch: 67/100... Training loss: 0.0978\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1050\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1000\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.0980\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.0964\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0973\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.0976\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0961\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0974\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.0971\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.0967\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1055\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0974\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.0964\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0948\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.0978\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.0965\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1047\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0983\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1048\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1051\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0952\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.0994\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0975\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1046\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0969\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0950\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.0980\n",
      "Epoch: 68/100... Training loss: 0.0992\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.0968\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.0981\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.0988\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0981\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.0974\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0962\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0965\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.0969\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1054\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0996\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1038\n",
      "Epoch: 69/100... Training loss: 0.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.0976\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.1062\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.0968\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.0984\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1059\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0966\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.0986\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1047\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0990\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.1078\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0979\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.0973\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.0978\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0965\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0974\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0965\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1043\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.0957\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1047\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0965\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0975\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.0958\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.0954\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.1045\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.0974\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1049\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0970\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0973\n",
      "Epoch: 70/100... Training loss: 0.0952\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1000\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.0978\n",
      "Epoch: 70/100... Training loss: 0.0988\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.0952\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.0960\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.1052\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.0977\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.0998\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.0967\n",
      "Epoch: 70/100... Training loss: 0.0986\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0979\n",
      "Epoch: 70/100... Training loss: 0.1043\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.0985\n",
      "Epoch: 70/100... Training loss: 0.1045\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1042\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0968\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0963\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0958\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0965\n",
      "Epoch: 71/100... Training loss: 0.0978\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1045\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.0968\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0967\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0972\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0975\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1057\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.0994\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.0976\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0990\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.0973\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0973\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0989\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.0982\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0944\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0985\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.0970\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.0950\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.0973\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1051\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1051\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1042\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0964\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0971\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100... Training loss: 0.0957\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.0970\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0965\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0977\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0968\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0957\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0948\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0969\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0977\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.0982\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.0972\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.0980\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0975\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1048\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.0984\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.0973\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0958\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.0976\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0978\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0942\n",
      "Epoch: 73/100... Training loss: 0.0965\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0967\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0966\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1048\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0967\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1035\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1048\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1035\n",
      "Epoch: 73/100... Training loss: 0.0966\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0967\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1051\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0972\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.0979\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.0955\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0976\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0962\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0970\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.0965\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0967\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0977\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1046\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1070\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.0956\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0949\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1038\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0987\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.0984\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.0963\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.0981\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.0983\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0971\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1054\n",
      "Epoch: 73/100... Training loss: 0.1042\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.0974\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0964\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0977\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0957\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1039\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0963\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.0974\n",
      "Epoch: 74/100... Training loss: 0.0960\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0959\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0956\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0972\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.0967\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1035\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.0958\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0973\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0983\n",
      "Epoch: 74/100... Training loss: 0.0969\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.0981\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.0975\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.0971\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1035\n",
      "Epoch: 74/100... Training loss: 0.0966\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1001\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.1062\n",
      "Epoch: 74/100... Training loss: 0.0978\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1047\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0963\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0976\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0966\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1042\n",
      "Epoch: 75/100... Training loss: 0.1040\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.0972\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.1045\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1034\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0976\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0965\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0975\n",
      "Epoch: 75/100... Training loss: 0.1038\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1063\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0962\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.0985\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.0958\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0968\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.0976\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.1047\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.0966\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.0976\n",
      "Epoch: 75/100... Training loss: 0.0988\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.0979\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1059\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0977\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1030\n",
      "Epoch: 76/100... Training loss: 0.1038\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0950\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0954\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0958\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0966\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0957\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0969\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1048\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0973\n",
      "Epoch: 76/100... Training loss: 0.0973\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.0962\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0974\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0967\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.0959\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.0952\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.0970\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0996\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0979\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.1038\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1052\n",
      "Epoch: 76/100... Training loss: 0.0994\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.0981\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.0956\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.0960\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.0980\n",
      "Epoch: 76/100... Training loss: 0.0977\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0975\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0972\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.0991\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.0986\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.0978\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1056\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0960\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0948\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0959\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1031\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.0965\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0958\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0968\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0981\n",
      "Epoch: 77/100... Training loss: 0.0953\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0974\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0964\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1049\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1043\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.0969\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.1040\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.0971\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0972\n",
      "Epoch: 77/100... Training loss: 0.0993\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1041\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.0990\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.1039\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1040\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.0963\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1046\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0982\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.0972\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0971\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.0962\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1035\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0964\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0976\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.0966\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0980\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1046\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.0957\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.0960\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0970\n",
      "Epoch: 78/100... Training loss: 0.0943\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0984\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.0974\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0981\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0973\n",
      "Epoch: 78/100... Training loss: 0.0961\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0978\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.0975\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0990\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0959\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0969\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1048\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1044\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0971\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1039\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0961\n",
      "Epoch: 79/100... Training loss: 0.0955\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1036\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0969\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1046\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1039\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0967\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.0947\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.0968\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0965\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0985\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0950\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.0960\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.0970\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0978\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.0957\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0996\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0989\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0976\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0956\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1059\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.1040\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.1056\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1043\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.1034\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.0966\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1034\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1057\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.0968\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0976\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.0956\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1063\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0974\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.0953\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.0965\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0957\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0971\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.0992\n",
      "Epoch: 80/100... Training loss: 0.0968\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.0955\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0961\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.1047\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0970\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.0960\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.0973\n",
      "Epoch: 80/100... Training loss: 0.0961\n",
      "Epoch: 80/100... Training loss: 0.0975\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1040\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1043\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.0969\n",
      "Epoch: 81/100... Training loss: 0.0983\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0946\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0963\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1053\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0950\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0957\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0960\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.0964\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.0955\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.0967\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0982\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1028\n",
      "Epoch: 81/100... Training loss: 0.0971\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1052\n",
      "Epoch: 81/100... Training loss: 0.1047\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0955\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1046\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.0985\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0978\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0966\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.0960\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0974\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.0965\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1037\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0948\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.0975\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0969\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0973\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0969\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0953\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0969\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.0979\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1057\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0959\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0980\n",
      "Epoch: 82/100... Training loss: 0.0972\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0967\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.0961\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1044\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.0978\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0965\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.0954\n",
      "Epoch: 82/100... Training loss: 0.0975\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.0957\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0974\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0968\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0974\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0956\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0949\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0968\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1042\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0955\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.0965\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0955\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.1052\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0954\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.1044\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.0995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0992\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0983\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.0960\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1045\n",
      "Epoch: 83/100... Training loss: 0.0950\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.0982\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0990\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.0991\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0977\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0950\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0969\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0980\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.0971\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0988\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0981\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.0967\n",
      "Epoch: 83/100... Training loss: 0.0972\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.0973\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1036\n",
      "Epoch: 84/100... Training loss: 0.0966\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0945\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0961\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.1046\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1043\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1038\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0973\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.0957\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1031\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1057\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1041\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1043\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.0948\n",
      "Epoch: 84/100... Training loss: 0.0968\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.0950\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.0978\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.0975\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.0993\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1041\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0990\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0977\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.1038\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1042\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0967\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1042\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0938\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.0954\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0970\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0992\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0972\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0962\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0971\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.0958\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1048\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0962\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0977\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.0955\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.0960\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0973\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0956\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1045\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1039\n",
      "Epoch: 86/100... Training loss: 0.1029\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.0957\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1029\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.1045\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0959\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.0952\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1035\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0978\n",
      "Epoch: 86/100... Training loss: 0.0953\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0983\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1041\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0982\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0964\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0956\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.0951\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0960\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.0966\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1044\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0968\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1052\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.0984\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0981\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0958\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.1029\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0947\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0952\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.0961\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1039\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.0977\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.0950\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0960\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1037\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0919\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1044\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1043\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.0982\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0978\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0965\n",
      "Epoch: 87/100... Training loss: 0.0963\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0950\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.1076\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.0968\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1031\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0961\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0959\n",
      "Epoch: 87/100... Training loss: 0.0971\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0966\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0957\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0972\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.0939\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0958\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.0959\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1030\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0959\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1037\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.0955\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1036\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0973\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0960\n",
      "Epoch: 88/100... Training loss: 0.1040\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.1042\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0982\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0958\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0949\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.0989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.0968\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0955\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1044\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.0969\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0979\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1030\n",
      "Epoch: 88/100... Training loss: 0.0971\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.0951\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0970\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.0966\n",
      "Epoch: 88/100... Training loss: 0.0978\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0949\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.0972\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0955\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0964\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1054\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0953\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0976\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.1014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0959\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.1031\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1034\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.0969\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.0966\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.1034\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0961\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0977\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0968\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.0970\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.0971\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.0979\n",
      "Epoch: 89/100... Training loss: 0.0957\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0949\n",
      "Epoch: 90/100... Training loss: 0.0959\n",
      "Epoch: 90/100... Training loss: 0.1047\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0960\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1035\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0947\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1039\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.0968\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0962\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0974\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.0983\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.0977\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0962\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.1038\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1048\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.0966\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0958\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.1051\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0969\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1043\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1051\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1045\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0957\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0951\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0955\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1052\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0958\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0975\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0945\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0959\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0969\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1046\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0965\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.0963\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0951\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0949\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1045\n",
      "Epoch: 91/100... Training loss: 0.0972\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1041\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.0966\n",
      "Epoch: 91/100... Training loss: 0.1036\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1036\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.0974\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0952\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.1049\n",
      "Epoch: 91/100... Training loss: 0.0985\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0968\n",
      "Epoch: 91/100... Training loss: 0.1035\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1040\n",
      "Epoch: 91/100... Training loss: 0.0979\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0984\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0951\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.0942\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0957\n",
      "Epoch: 92/100... Training loss: 0.0948\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0953\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0969\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1038\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0965\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1040\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1038\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0943\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.1042\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1034\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0960\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.0973\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0942\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1028\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.0962\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1034\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0968\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.1005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0979\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1034\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0940\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0950\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1034\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0962\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1034\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1046\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0978\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1034\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1034\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1035\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0957\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1032\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100... Training loss: 0.0953\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0958\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.0954\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.0963\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0951\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.0968\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0951\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.0967\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0974\n",
      "Epoch: 93/100... Training loss: 0.0959\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.0983\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1045\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1047\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0957\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.0950\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1049\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1043\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0964\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1038\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1032\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0969\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0955\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0959\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0965\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0966\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0958\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1038\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.0954\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0958\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0986\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0974\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0957\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0962\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0976\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0972\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1054\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.0971\n",
      "Epoch: 94/100... Training loss: 0.0975\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1041\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.0955\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0977\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0961\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0945\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.0968\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0960\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1034\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1029\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0970\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0961\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0931\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0965\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1061\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0930\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0959\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0937\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0960\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0942\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.0960\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.0949\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1034\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0973\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0971\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.0960\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0975\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1037\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.0951\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0964\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1046\n",
      "Epoch: 95/100... Training loss: 0.0967\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1039\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0972\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0969\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.0981\n",
      "Epoch: 95/100... Training loss: 0.0989\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.0951\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.1049\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0947\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0944\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0956\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0958\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1051\n",
      "Epoch: 96/100... Training loss: 0.1035\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1031\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1035\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0960\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0953\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0948\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.0959\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0954\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0973\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0955\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0974\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0963\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0976\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.0951\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.0952\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0954\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.0966\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.0979\n",
      "Epoch: 96/100... Training loss: 0.0961\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.1038\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0932\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0947\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1040\n",
      "Epoch: 96/100... Training loss: 0.0969\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0968\n",
      "Epoch: 96/100... Training loss: 0.0967\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1041\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1029\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0955\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.0959\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0959\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.1036\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0958\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0943\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0956\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0949\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1045\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0953\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0968\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0969\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0964\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.0970\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0952\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.0967\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0962\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0954\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.0965\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1039\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1029\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.0953\n",
      "Epoch: 97/100... Training loss: 0.1047\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100... Training loss: 0.1034\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.0966\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0961\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0963\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1041\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1029\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0961\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0957\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0952\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1049\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0946\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0952\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0967\n",
      "Epoch: 98/100... Training loss: 0.0968\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1036\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0978\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1037\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0963\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1052\n",
      "Epoch: 98/100... Training loss: 0.0971\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0962\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0994\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0947\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.0970\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.0991\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0976\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.1043\n",
      "Epoch: 99/100... Training loss: 0.0954\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0979\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0943\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.0958\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.0957\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0962\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0967\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.0936\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0961\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1033\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0975\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1043\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0955\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1030\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0954\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1035\n",
      "Epoch: 99/100... Training loss: 0.1039\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0969\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0979\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0966\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0942\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1027\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.0994\n",
      "Epoch: 99/100... Training loss: 0.0960\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0972\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0945\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0959\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1033\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.0974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.0946\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.1030\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0966\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1030\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0978\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0954\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1030\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.1037\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1036\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0968\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.0971\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.0952\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1039\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.0977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1038\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.0940\n",
      "Epoch: 100/100... Training loss: 0.0964\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0961\n",
      "Epoch: 100/100... Training loss: 0.0956\n",
      "Epoch: 100/100... Training loss: 0.0975\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0970\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0950\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1053\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.1045\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1027\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 200\n",
    "# Set's how much noise we're adding to the MNIST images\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        # Get images from the batch\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to the input images\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the performance\n",
    "\n",
    "Here I'm adding noise to the test images and passing them through the autoencoder. It does a suprisingly great job of removing the noise, even though it's sometimes difficult to tell what the original number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + noise_factor * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
