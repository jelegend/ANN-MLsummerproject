{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Classification Model [GPU].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLAVPpMObd4tu2DguRJckm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jelegend/ANN-MLsummerproject/blob/master/MNIST_Classification_Model_%5BGPU%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dFDbjdQtLD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import functional\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hof2sYC_kqcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grayscale and inline plotting\n",
        "%matplotlib inline\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L84MUGurkreA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "    nr, nc = image.shape\n",
        "    extent = [-0.5, nc - 0.5, nr - 0.5, -0.5]\n",
        "    plt.imshow(image, extent=extent, origin='upper', interpolation='nearest')\n",
        "\n",
        "def visualize(t, loss, errcl, x5, x4, x3, x0, w1):\n",
        "\n",
        "    loss_avg = np.divide(\n",
        "        np.cumsum(loss[: t + 1]),\n",
        "        range(1, t + 2)\n",
        "    )\n",
        "\n",
        "    errcl_avg = np.divide(\n",
        "        np.cumsum(errcl[: t + 1]),\n",
        "        range(1, t + 2)\n",
        "    )\n",
        "\n",
        "    n_last_batches = np.min([20, t])\n",
        "    k = np.ones(n_last_batches * 2 + 1) / (n_last_batches + 1)\n",
        "    k[:n_last_batches] = 0\n",
        "    \n",
        "    errcl_sm = np.convolve(np.pad(errcl, mode=\"edge\", pad_width=n_last_batches), k, mode=\"valid\")\n",
        "    errcl_sm = errcl_sm[: len(errcl_avg)]\n",
        "\n",
        "    loss_sm = np.convolve(np.pad(loss, mode=\"edge\", pad_width=n_last_batches), k, mode=\"valid\")\n",
        "    loss_sm = loss_sm[: len(loss)]\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.subplot(4, 3, 1)\n",
        "    plt.plot(loss, label=\"loss\")\n",
        "    plt.plot(loss_sm, label=\"smothed loss\")\n",
        "    plt.plot(loss_avg, label=\"avg loss\")\n",
        "    plt.legend()\n",
        "    plt.ylim(0, np.max(loss)*1.05)\n",
        "    plt.title(\"loss: avg - %.4f, smoothed - %.4f, current - %.4f\"  % (loss_avg[t], loss_sm[t], loss[t]))\n",
        "\n",
        "    plt.subplot(4, 3, 2)\n",
        "    plt.plot(errcl, label=\"cl err\")\n",
        "    plt.plot(errcl_sm, label=\"smothed cl err\")\n",
        "    plt.plot(errcl_avg, label=\"avg cl err\")\n",
        "    plt.legend()\n",
        "    plt.ylim(0, np.max(errcl)*1.05)\n",
        "    plt.title(\"cl error: avg - %.4f, smoothed - %.4f, current - %.4f\"  % (errcl_avg[t], errcl_sm[t], errcl[t]))\n",
        "    \n",
        "    plt.subplot(4, 3, 3)\n",
        "    plt.bar(range(len(x5)), x5)\n",
        "    plt.title(\"class confidences\")\n",
        "\n",
        "    plt.subplot(4,3,4)\n",
        "    plt.hist(x4)\n",
        "    plt.title(\"F6 activations\")\n",
        "\n",
        "    plt.subplot(4,3,5)\n",
        "    plt.hist(x3)\n",
        "    plt.title(\"C5 activations\")\n",
        "\n",
        "    plt.subplot(4,3,6)\n",
        "    plot_image(x0)\n",
        "    plt.title(\"input image\")\n",
        "\n",
        "    for i in range(w1.shape[0]):\n",
        "        plt.subplot(4,3,7+i)\n",
        "        plot_image(w1[i])\n",
        "        plt.title(\"C1 kernel channel \" + str(i))\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5)\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.gcf().set_size_inches(18.5, 10.5)\n",
        "    display.display(plt.gcf())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-blJng0tSdI",
        "colab_type": "code",
        "outputId": "3c3ce795-9554-41d2-9fd7-62537e0c8651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "mnist = torchvision.datasets.MNIST(root='data', train=True, download=True) # train data only\n",
        "trainimages = mnist.data\n",
        "trainlabels = mnist.targets\n",
        "\n",
        "# check training data shape\n",
        "print (\"Training Data shape is: \", list(trainimages.size()))\n",
        "print (\"Training Target shape is: \", list(trainlabels.size()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data shape is:  [60000, 28, 28]\n",
            "Training Target shape is:  [60000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnYtckBNtvXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        # convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32, kernel_size=(3,3), stride=1)\n",
        "        # convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3), stride=1)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size = (2,2),stride=2)\n",
        "        # dropout layer 1 (p=0.25)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        # linear layer (9216 -> 128)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        # dropout layer 2 (p=0.5)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        # linear layer (500 -> 10)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "       # add sequence of convolutional and max pooling layers\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        #Flattening the output for the Linear layers\n",
        "        x = x.view(x.size(0),-1) \n",
        "        #Dropout Layer\n",
        "        x = self.dropout1(x)\n",
        "        #Linear fully-connected layer and ReLU\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        #Dropout Layer\n",
        "        x = self.dropout2(x)\n",
        "        #Linear fully-connected layer and Softmax\n",
        "        x = torch.softmax(self.fc2(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkXvZ6cMzEdh",
        "colab_type": "code",
        "outputId": "439a31ba-f1f9-4195-b89d-3487f0ddbee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "ntrain = trainimages.shape[0];  # number of training examples\n",
        "nepoch = 10;                    # number of epochs through training set\n",
        "disp_freq = 100                 # display frequency\n",
        "batchsize = 32                  # minibatch size\n",
        "\n",
        "errs = []\n",
        "losses = []\n",
        "\n",
        "net = Network()\n",
        "\n",
        "# use SGD optimizer, set learning rate parameter as 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum = 0.9)\n",
        "\n",
        "t_start = time.time()\n",
        "for iepoch in range(nepoch):\n",
        "    for t in range(int(ntrain / batchsize)):\n",
        "        batchindices = np.random.choice(ntrain, batchsize, replace=False)\n",
        "        trainlabels_iter = trainlabels[batchindices]\n",
        "        \n",
        "        # label 1 for the correct digit and -1 for the incorrect digits\n",
        "        y = torch.ones(10, batchsize) * (-1)\n",
        "        y[trainlabels_iter, torch.arange(batchsize, dtype=torch.int64)] = 1\n",
        "\n",
        "        # normalize input images\n",
        "        imgs = torch.zeros([batchsize, 1, 28, 28])\n",
        "        imgs[:, 0, 2: -2, 2: -2] = trainimages[batchindices].float() / 255.\n",
        "\n",
        "        # before the forward pass, clean the gradient buffers of all parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        out = net(imgs)\n",
        "        \n",
        "        # MSE loss\n",
        "        loss = criterion(out, y)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters using SGD\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculate error rate and loss for plot\n",
        "        pred = torch.argmax(out, dim=1)\n",
        "        err = torch.mean((pred != trainlabels_iter).float())\n",
        "        errs.append(err.detach().numpy())\n",
        "        losses.append(loss.detach().numpy())\n",
        "\n",
        "        \n",
        "        # plots\n",
        "        if (t + 1) % disp_freq == 0:\n",
        "            plt.gcf().clear()\n",
        "            visualize(len(errs) - 1, losses, errs, out[0,:].detach(), lenet5.record[\"F6\"][:, 0], \n",
        "                      lenet5.record[\"C5\"][:, 0], imgs[0, 0].detach(), lenet5.C1.weight.detach().squeeze())\n",
        "            print(str(time.time() - t_start) + \" seconds per \" + str(disp_freq) + \" iterations\")\n",
        "            t_start = time.time()\n",
        "            time.sleep(0.01)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a4f514bd6019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# normalize input images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# before the forward pass, clean the gradient buffers of all parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (24) must match the existing size (28) at non-singleton dimension 2.  Target sizes: [32, 24, 24].  Tensor sizes: [32, 28, 28]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOaUw6rnnTTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}