{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Classification Model [GPU].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEDkem/K9k2gJO2kE6B5dA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jelegend/ANN-MLsummerproject/blob/master/MNIST_Classification_Model_%5BGPU%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dFDbjdQtLD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import functional\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hof2sYC_kqcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grayscale and inline plotting\n",
        "%matplotlib inline\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L84MUGurkreA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "    nr, nc = image.shape\n",
        "    extent = [-0.5, nc - 0.5, nr - 0.5, -0.5]\n",
        "    plt.imshow(image, extent=extent, origin='upper', interpolation='nearest')\n",
        "\n",
        "def visualize(t, loss, errcl, x5, x4, x3, x0, w1):\n",
        "\n",
        "    loss_avg = np.divide(\n",
        "        np.cumsum(loss[: t + 1]),\n",
        "        range(1, t + 2)\n",
        "    )\n",
        "\n",
        "    errcl_avg = np.divide(\n",
        "        np.cumsum(errcl[: t + 1]),\n",
        "        range(1, t + 2)\n",
        "    )\n",
        "\n",
        "    n_last_batches = np.min([20, t])\n",
        "    k = np.ones(n_last_batches * 2 + 1) / (n_last_batches + 1)\n",
        "    k[:n_last_batches] = 0\n",
        "    \n",
        "    errcl_sm = np.convolve(np.pad(errcl, mode=\"edge\", pad_width=n_last_batches), k, mode=\"valid\")\n",
        "    errcl_sm = errcl_sm[: len(errcl_avg)]\n",
        "\n",
        "    loss_sm = np.convolve(np.pad(loss, mode=\"edge\", pad_width=n_last_batches), k, mode=\"valid\")\n",
        "    loss_sm = loss_sm[: len(loss)]\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.subplot(4, 3, 1)\n",
        "    plt.plot(loss, label=\"loss\")\n",
        "    plt.plot(loss_sm, label=\"smothed loss\")\n",
        "    plt.plot(loss_avg, label=\"avg loss\")\n",
        "    plt.legend()\n",
        "    plt.ylim(0, np.max(loss)*1.05)\n",
        "    plt.title(\"loss: avg - %.4f, smoothed - %.4f, current - %.4f\"  % (loss_avg[t], loss_sm[t], loss[t]))\n",
        "\n",
        "    plt.subplot(4, 3, 2)\n",
        "    plt.plot(errcl, label=\"cl err\")\n",
        "    plt.plot(errcl_sm, label=\"smothed cl err\")\n",
        "    plt.plot(errcl_avg, label=\"avg cl err\")\n",
        "    plt.legend()\n",
        "    plt.ylim(0, np.max(errcl)*1.05)\n",
        "    plt.title(\"cl error: avg - %.4f, smoothed - %.4f, current - %.4f\"  % (errcl_avg[t], errcl_sm[t], errcl[t]))\n",
        "    \n",
        "    plt.subplot(4, 3, 3)\n",
        "    plt.bar(range(len(x5)), x5)\n",
        "    plt.title(\"class confidences\")\n",
        "\n",
        "    plt.subplot(4,3,4)\n",
        "    plt.hist(x4)\n",
        "    plt.title(\"F6 activations\")\n",
        "\n",
        "    plt.subplot(4,3,5)\n",
        "    plt.hist(x3)\n",
        "    plt.title(\"C5 activations\")\n",
        "\n",
        "    plt.subplot(4,3,6)\n",
        "    plot_image(x0)\n",
        "    plt.title(\"input image\")\n",
        "\n",
        "    for i in range(w1.shape[0]):\n",
        "        plt.subplot(4,3,7+i)\n",
        "        plot_image(w1[i])\n",
        "        plt.title(\"C1 kernel channel \" + str(i))\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5)\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.gcf().set_size_inches(18.5, 10.5)\n",
        "    display.display(plt.gcf())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-blJng0tSdI",
        "colab_type": "code",
        "outputId": "4cd65b19-6170-44b9-9c71-654d1e6dd657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "\n",
        "mnist = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=transform) # train data only\n",
        "trainimages = mnist.data\n",
        "trainlabels = mnist.targets\n",
        "\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(mnist, batch_size=32, shuffle=True)\n",
        "\n",
        "# check training data shape\n",
        "print (\"Training Data shape is: \", list(trainimages.size()))\n",
        "print (\"Training Target shape is: \", list(trainlabels.size()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data shape is:  [60000, 28, 28]\n",
            "Training Target shape is:  [60000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnYtckBNtvXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        # convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=32, kernel_size=(3,3), stride=1)\n",
        "        # convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3), stride=1)\n",
        "        # max pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size = (2,2),stride=2)\n",
        "        # dropout layer 1 (p=0.25)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        # linear layer (9216 -> 128)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        # dropout layer 2 (p=0.5)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        # linear layer (500 -> 10)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "       # add sequence of convolutional and max pooling layers\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        #Flattening the output for the Linear layers\n",
        "        x = x.view(x.size(0),-1) \n",
        "        #Dropout Layer\n",
        "        x = self.dropout1(x)\n",
        "        #Linear fully-connected layer and ReLU\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        #Dropout Layer\n",
        "        x = self.dropout2(x)\n",
        "        #Linear fully-connected layer and Softmax\n",
        "        x = torch.softmax(self.fc2(x), dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "net = Network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTTJzenusTN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkXvZ6cMzEdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOaUw6rnnTTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}